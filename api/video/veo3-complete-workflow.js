const fetch = require('node-fetch');
const fs = require('fs');
const path = require('path');
const { exec } = require('child_process');
const { promisify } = require('util');

const execAsync = promisify(exec);

// ChatGPT API configuration
const OPENAI_API_KEY = process.env.OPENAI_API_KEY || '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';

/**
 * Workflow ho√†n ch·ªânh: Video g·ªëc ‚Üí Ph√¢n t√≠ch ‚Üí ChatGPT refine ‚Üí Veo3 ‚Üí K·∫øt qu·∫£
 * @param {string} videoPath - ƒê∆∞·ªùng d·∫´n video g·ªëc
 * @param {Object} options - T√πy ch·ªçn
 * @returns {Promise<Object>} - K·∫øt qu·∫£ ho√†n ch·ªânh
 */
async function veo3CompleteWorkflow(videoPath, options = {}) {
    try {
        console.log(`üé¨ [veo3CompleteWorkflow] B·∫Øt ƒë·∫ßu workflow ho√†n ch·ªânh cho: ${videoPath}`);
        
        const {
            startSecond = 0,
            duration = 8,
            frameInterval = 1,
            maxFrames = 8,
            outputDir = './temp/veo3-complete',
            themeContext = null
        } = options;
        
        // T·∫°o th∆∞ m·ª•c output
        if (!fs.existsSync(outputDir)) {
            fs.mkdirSync(outputDir, { recursive: true });
        }
        
        // Step 1: T·∫°o segment 8s t·ª´ video g·ªëc
        console.log(`‚úÇÔ∏è [Step 1] T·∫°o segment 8s t·ª´ gi√¢y ${startSecond}...`);
        const segmentPath = path.join(outputDir, `segment_${startSecond}s-${startSecond + duration}s.mp4`);
        
        const ffmpegCmd = `ffmpeg -i "${videoPath}" -ss ${startSecond} -t ${duration} -c copy -avoid_negative_ts make_zero "${segmentPath}"`;
        await execAsync(ffmpegCmd);
        
        console.log(`‚úÖ [Step 1] ƒê√£ t·∫°o segment: ${segmentPath}`);
        
        // Step 2: Tr√≠ch xu·∫•t frames
        console.log(`üì∏ [Step 2] Tr√≠ch xu·∫•t frames...`);
        const framesDir = path.join(outputDir, 'frames');
        if (!fs.existsSync(framesDir)) {
            fs.mkdirSync(framesDir, { recursive: true });
        }
        
        const ffmpegFramesCmd = `ffmpeg -i "${segmentPath}" -vf fps=1/${frameInterval} -frames:v ${maxFrames} "${framesDir}/frame_%03d.jpg"`;
        await execAsync(ffmpegFramesCmd);
        
        // L·∫•y danh s√°ch frames
        const frames = [];
        const files = fs.readdirSync(framesDir);
        const frameFiles = files.filter(file => file.startsWith('frame_') && file.endsWith('.jpg'));
        
        for (let i = 0; i < frameFiles.length; i++) {
            const frameFile = frameFiles[i];
            const framePath = path.join(framesDir, frameFile);
            const frameTime = i * frameInterval;
            
            frames.push({
                index: i,
                time: frameTime,
                filename: frameFile,
                path: framePath
            });
        }
        
        console.log(`‚úÖ [Step 2] ƒê√£ tr√≠ch xu·∫•t ${frames.length} frames`);
        
        // Step 3: Ph√¢n t√≠ch frames v·ªõi ChatGPT Vision
        console.log(`üîç [Step 3] Ph√¢n t√≠ch frames v·ªõi ChatGPT Vision...`);
        const detailedAnalysis = [];
        
        for (let i = 0; i < frames.length; i++) {
            const frame = frames[i];
            const second = i + 1;
            
            console.log(`üîç [Step 3] Ph√¢n t√≠ch frame ${second}/${frames.length}`);
            
            // Chu·∫©n b·ªã image cho ChatGPT Vision
            let imageContent = null;
            if (fs.existsSync(frame.path)) {
                const imageBuffer = fs.readFileSync(frame.path);
                const base64Image = imageBuffer.toString('base64');
                imageContent = {
                    type: "image_url",
                    image_url: {
                        url: `data:image/jpeg;base64,${base64Image}`,
                        detail: "high"
                    }
                };
            }
            
            // T·∫°o prompt chi ti·∫øt cho t·ª´ng frame v·ªõi ch·ªß ƒë·ªÅ chung
            const themeContextText = themeContext ? `
            
            CH·ª¶ ƒê·ªÄ CHUNG C·ª¶A VIDEO:
            - Ch·ªß ƒë·ªÅ ch√≠nh: ${themeContext.mainTheme}
            - ƒê·ªãa ƒëi·ªÉm: ${themeContext.location}
            - Phong c√°ch visual: ${themeContext.visualStyle}
            - M√†u s·∫Øc ch·ªß ƒë·∫°o: ${themeContext.colorPalette?.join(', ') || 'N/A'}
            - T√¢m tr·∫°ng: ${themeContext.mood}
            - T√≠nh li√™n k·∫øt: ${themeContext.continuity}
            - H∆∞·ªõng ph√°t tri·ªÉn: ${themeContext.sceneProgression}
            - N·ªôi dung t√≥m t·∫Øt: ${themeContext.contentSummary || 'N/A'}
            - Prompt t·ªïng th·ªÉ: ${themeContext.unifiedPrompt || 'N/A'}
            
            Y√äU C·∫¶U: ƒê·∫£m b·∫£o ph√¢n t√≠ch v√† prompt ph√π h·ª£p v·ªõi ch·ªß ƒë·ªÅ chung v√† n·ªôi dung th·ª±c t·∫ø n√†y.` : '';
            
            const systemPrompt = `B·∫°n l√† chuy√™n gia ph√¢n t√≠ch video frame-by-frame v·ªõi kh·∫£ nƒÉng m√¥ t·∫£ c·ª±c k·ª≥ chi ti·∫øt.
            
            Nhi·ªám v·ª•: Ph√¢n t√≠ch frame n√†y (gi√¢y ${second}) v√† m√¥ t·∫£ CHI TI·∫æT t·ª´ng element, t·ª´ng chi ti·∫øt nh·ªè nh·∫•t.${themeContextText}
            
            Y√™u c·∫ßu m√¥ t·∫£ chi ti·∫øt:
            1. M√¥ t·∫£ t·ª´ng object, m√†u s·∫Øc, texture, √°nh s√°ng
            2. Ph√¢n t√≠ch composition, perspective, depth
            3. M√¥ t·∫£ camera angle, movement, focus
            4. Ph√¢n t√≠ch mood, atmosphere, emotion
            5. T·∫°o prompt Veo3 c·ª±c k·ª≥ chi ti·∫øt v√† c·ª• th·ªÉ
            6. ƒê·∫£m b·∫£o ph√π h·ª£p v·ªõi ch·ªß ƒë·ªÅ chung c·ªßa video
            
            Tr·∫£ v·ªÅ JSON format:
            {
                "second": ${second},
                "description": "m√¥ t·∫£ CHI TI·∫æT t·ª´ng element trong frame",
                "visual_elements": ["element1 v·ªõi m√¥ t·∫£ chi ti·∫øt", "element2 v·ªõi m√¥ t·∫£ chi ti·∫øt"],
                "colors": ["#color1 v·ªõi m√¥ t·∫£", "#color2 v·ªõi m√¥ t·∫£"],
                "textures": ["texture1", "texture2"],
                "lighting": "m√¥ t·∫£ chi ti·∫øt √°nh s√°ng",
                "shadows": "m√¥ t·∫£ chi ti·∫øt b√≥ng ƒë·ªï",
                "composition": "m√¥ t·∫£ chi ti·∫øt composition",
                "perspective": "m√¥ t·∫£ chi ti·∫øt perspective",
                "depth": "m√¥ t·∫£ chi ti·∫øt depth",
                "camera_angle": "m√¥ t·∫£ chi ti·∫øt g√≥c m√°y",
                "camera_movement": "m√¥ t·∫£ chi ti·∫øt chuy·ªÉn ƒë·ªông m√°y",
                "focus": "m√¥ t·∫£ chi ti·∫øt focus",
                "mood": "m√¥ t·∫£ chi ti·∫øt mood v√† atmosphere",
                "emotion": "m√¥ t·∫£ chi ti·∫øt c·∫£m x√∫c",
                "atmosphere": "m√¥ t·∫£ chi ti·∫øt kh√¥ng kh√≠",
                "veo3_prompt": "PROMPT C·ª∞C K·ª≤ CHI TI·∫æT cho Veo3 v·ªõi t·ª´ng element c·ª• th·ªÉ, ph√π h·ª£p v·ªõi ch·ªß ƒë·ªÅ chung",
                "continuity": "m√¥ t·∫£ chi ti·∫øt c√°ch k·∫øt n·ªëi v·ªõi frame tr∆∞·ªõc/sau",
                "themeConsistency": "c√°ch frame n√†y ph√π h·ª£p v·ªõi ch·ªß ƒë·ªÅ chung"
            }`;

            const userPrompt = `Ph√¢n t√≠ch frame n√†y (gi√¢y ${second}) v√† t·∫°o m√¥ t·∫£ chi ti·∫øt cho Veo3.`;

            const messages = [
                { role: "system", content: systemPrompt },
                { role: "user", content: userPrompt }
            ];

            if (imageContent) {
                messages[1].content = [
                    { type: "text", text: userPrompt },
                    imageContent
                ];
            }

            try {
                const response = await fetch('https://api.openai.com/v1/chat/completions', {
                    method: 'POST',
                    headers: {
                        'Authorization': `Bearer ${OPENAI_API_KEY}`,
                        'Content-Type': 'application/json'
                    },
                    body: JSON.stringify({
                        model: 'gpt-4o-mini',
                        messages: messages,
                        max_tokens: 2000,
                        temperature: 0.7
                    })
                });

                const data = await response.json();
                
                if (data.choices && data.choices[0] && data.choices[0].message) {
                    const analysisText = data.choices[0].message.content;
                    console.log(`‚úÖ [Step 3] ChatGPT response cho frame ${second}`);
                    
                    // Parse JSON t·ª´ response
                    try {
                        const jsonMatch = analysisText.match(/\{[\s\S]*\}/);
                        if (jsonMatch) {
                            const analysis = JSON.parse(jsonMatch[0]);
                            detailedAnalysis.push({
                                second: second,
                                analysis: analysis,
                                rawResponse: analysisText
                            });
                        } else {
                            throw new Error('No JSON found in response');
                        }
                    } catch (parseError) {
                        console.warn(`‚ö†Ô∏è [Step 3] Kh√¥ng th·ªÉ parse JSON cho frame ${second}, t·∫°o mock analysis`);
                        
                        // Mock analysis fallback
                        const mockAnalysis = {
                            second: second,
                            description: `Frame ${second} - Professional scene with clean composition`,
                            visual_elements: ["Professional elements", "Clean design"],
                            colors: ["#ffffff", "#000000"],
                            textures: ["smooth", "professional"],
                            lighting: "Professional lighting",
                            shadows: "Soft shadows",
                            composition: "Clean composition",
                            perspective: "Professional perspective",
                            depth: "Good depth",
                            camera_angle: "Professional angle",
                            camera_movement: "Smooth movement",
                            focus: "Sharp focus",
                            mood: "Professional mood",
                            emotion: "Confident emotion",
                            atmosphere: "Professional atmosphere",
                            veo3_prompt: `Create a professional video scene with clean composition, modern lighting, and dynamic camera movement for frame ${second}`,
                            continuity: "Smooth continuity"
                        };
                        
                        detailedAnalysis.push({
                            second: second,
                            analysis: mockAnalysis,
                            rawResponse: analysisText
                        });
                    }
                } else {
                    throw new Error('Invalid ChatGPT response');
                }
                
            } catch (chatError) {
                console.warn(`‚ö†Ô∏è [Step 3] ChatGPT error cho frame ${second}:`, chatError.message);
                
                // Mock analysis fallback
                const mockAnalysis = {
                    second: second,
                    description: `Frame ${second} - Professional scene with clean composition`,
                    visual_elements: ["Professional elements", "Clean design"],
                    colors: ["#ffffff", "#000000"],
                    textures: ["smooth", "professional"],
                    lighting: "Professional lighting",
                    shadows: "Soft shadows",
                    composition: "Clean composition",
                    perspective: "Professional perspective",
                    depth: "Good depth",
                    camera_angle: "Professional angle",
                    camera_movement: "Smooth movement",
                    focus: "Sharp focus",
                    mood: "Professional mood",
                    emotion: "Confident emotion",
                    atmosphere: "Professional atmosphere",
                    veo3_prompt: `Create a professional video scene with clean composition, modern lighting, and dynamic camera movement for frame ${second}`,
                    continuity: "Smooth continuity"
                };
                
                detailedAnalysis.push({
                    second: second,
                    analysis: mockAnalysis,
                    rawResponse: `Mock analysis for frame ${second}`
                });
            }
        }
        
        console.log(`‚úÖ [Step 3] ƒê√£ ph√¢n t√≠ch ${detailedAnalysis.length} frames`);
        
        // Step 4: T·∫°o JSON format cho Veo3
        console.log(`üé¨ [Step 4] T·∫°o JSON format cho Veo3...`);
        const systemPrompt = `B·∫°n l√† chuy√™n gia t·∫°o timeline video cho Veo3.
        
        Nhi·ªám v·ª•: T·∫°o timeline JSON ho√†n ch·ªânh d·ª±a tr√™n ph√¢n t√≠ch chi ti·∫øt t·ª´ng frame.
        
        Format JSON y√™u c·∫ßu:
        [
            {
                "timeStart": 0,
                "timeEnd": 2,
                "action": "m√¥ t·∫£ h√†nh ƒë·ªông chi ti·∫øt",
                "cameraStyle": "g√≥c m√°y quay c·ª• th·ªÉ, chuy·ªÉn ƒë·ªông m√°y",
                "soundFocus": "m√¥ t·∫£ √¢m thanh",
                "visualDetails": "chi ti·∫øt visual, m√†u s·∫Øc, √°nh s√°ng"
            }
        ]
        
        Y√™u c·∫ßu:
        1. M·ªói segment 2 gi√¢y (timeStart, timeEnd)
        2. Action: m√¥ t·∫£ h√†nh ƒë·ªông c·ª• th·ªÉ v√† chi ti·∫øt
        3. CameraStyle: g√≥c m√°y quay C·ª§ TH·ªÇ (close-up, wide-shot, pan, zoom, tilt, dolly, etc.)
        4. SoundFocus: m√¥ t·∫£ √¢m thanh ph√π h·ª£p
        5. VisualDetails: chi ti·∫øt visual, m√†u s·∫Øc, √°nh s√°ng
        6. T·∫°o timeline li·ªÅn m·∫°ch v√† logic
        7. M·ªói segment ph·∫£i t·∫°o video 8 gi√¢y th√∫ v·ªã
        
        Tr·∫£ v·ªÅ JSON array ch√≠nh x√°c nh∆∞ format tr√™n.`;

        const userPrompt = `T·∫°o timeline JSON cho Veo3 d·ª±a tr√™n ph√¢n t√≠ch chi ti·∫øt:

DETAILED ANALYSIS (${detailedAnalysis.length} frames):
${detailedAnalysis.map((item, index) => {
    const analysis = item.analysis;
    return `Frame ${analysis.second}:
- Description: ${analysis.description}
- Visual elements: ${analysis.visual_elements?.join(', ') || 'N/A'}
- Colors: ${analysis.colors?.join(', ') || 'N/A'}
- Lighting: ${analysis.lighting}
- Camera angle: ${analysis.camera_angle}
- Mood: ${analysis.mood}
- Veo3 prompt: ${analysis.veo3_prompt}`;
}).join('\n\n')}

T·∫°o timeline JSON ho√†n ch·ªânh cho video 8 gi√¢y n√†y.`;

        const messages = [
            { role: "system", content: systemPrompt },
            { role: "user", content: userPrompt }
        ];

        const response = await fetch('https://api.openai.com/v1/chat/completions', {
            method: 'POST',
            headers: {
                'Authorization': `Bearer ${OPENAI_API_KEY}`,
                'Content-Type': 'application/json'
            },
            body: JSON.stringify({
                model: 'gpt-4o',
                messages: messages,
                max_tokens: 2000,
                temperature: 0.7
            })
        });

        const data = await response.json();
        
        if (data.choices && data.choices[0] && data.choices[0].message) {
            const timelineText = data.choices[0].message.content;
            console.log(`‚úÖ [Step 4] ChatGPT response cho timeline`);
            
            // Parse JSON t·ª´ response
            let timeline = [];
            try {
                const jsonMatch = timelineText.match(/\[[\s\S]*\]/);
                if (jsonMatch) {
                    timeline = JSON.parse(jsonMatch[0]);
                } else {
                    throw new Error('No JSON array found in response');
                }
            } catch (parseError) {
                console.warn(`‚ö†Ô∏è [Step 4] Kh√¥ng th·ªÉ parse JSON, t·∫°o mock timeline`);
                
                // Mock timeline fallback
                timeline = [
                    {
                        timeStart: 0,
                        timeEnd: 2,
                        action: "Professional scene with clean composition",
                        cameraStyle: "medium-shot, static camera",
                        soundFocus: "Professional background sound",
                        visualDetails: "Clean white and black color scheme with bright lighting"
                    },
                    {
                        timeStart: 2,
                        timeEnd: 4,
                        action: "Dynamic movement with modern elements",
                        cameraStyle: "panning shot, smooth movement",
                        soundFocus: "Dynamic ambient sound",
                        visualDetails: "Modern design with blue and white colors"
                    },
                    {
                        timeStart: 4,
                        timeEnd: 6,
                        action: "Close-up details with professional focus",
                        cameraStyle: "close-up, steady focus",
                        soundFocus: "Clear, focused audio",
                        visualDetails: "Sharp details with professional lighting"
                    },
                    {
                        timeStart: 6,
                        timeEnd: 8,
                        action: "Final professional conclusion",
                        cameraStyle: "wide-shot, smooth zoom out",
                        soundFocus: "Professional conclusion sound",
                        visualDetails: "Complete professional scene with balanced composition"
                    }
                ];
            }
            
            console.log(`‚úÖ [Step 4] ƒê√£ t·∫°o timeline v·ªõi ${timeline.length} segments`);
            
            // Step 5: ChatGPT refine prompt
            console.log(`ü§ñ [Step 5] ChatGPT refine prompt chi ti·∫øt...`);
            const refinePrompt = `B·∫°n l√† chuy√™n gia t·∫°o prompt video cho Veo3. 

Nhi·ªám v·ª•: T·∫°o m·ªôt prompt CHI TI·∫æT v√† ƒê·ªíNG NH·∫§T cho video 8 gi√¢y d·ª±a tr√™n ph√¢n t√≠ch t·ª´ng c·∫£nh.

PH√ÇN T√çCH G·ªêC:
${timeline.map((segment, index) => 
    `C·∫£nh ${index + 1} (${segment.timeStart}s-${segment.timeEnd}s): ${segment.action}`
).join('\n')}

Y√äU C·∫¶U:
1. T·∫°o prompt CHI TI·∫æT cho to√†n b·ªô video 8 gi√¢y
2. ƒê·∫£m b·∫£o T√çNH ƒê·ªíNG NH·∫§T gi·ªØa c√°c c·∫£nh
3. M√¥ t·∫£ r√µ r√†ng t·ª´ng gi√¢y (0-2s, 2-4s, 4-6s, 6-8s)
4. Bao g·ªìm camera style, lighting, colors, mood
5. T·∫°o c·∫£m gi√°c LI·ªÄN M·∫†CH v√† LOGIC
6. Prompt ph·∫£i d√†i √≠t nh·∫•t 200 t·ª´

Tr·∫£ v·ªÅ prompt ho√†n ch·ªânh cho Veo3:`;

            const refineResponse = await fetch('https://api.openai.com/v1/chat/completions', {
                method: 'POST',
                headers: {
                    'Authorization': `Bearer ${OPENAI_API_KEY}`,
                    'Content-Type': 'application/json'
                },
                body: JSON.stringify({
                    model: 'gpt-4o',
                    messages: [
                        { role: 'system', content: 'B·∫°n l√† chuy√™n gia t·∫°o prompt video cho Veo3 v·ªõi kh·∫£ nƒÉng m√¥ t·∫£ chi ti·∫øt v√† ƒë·ªìng nh·∫•t.' },
                        { role: 'user', content: refinePrompt }
                    ],
                    max_tokens: 1000,
                    temperature: 0.7
                })
            });
            
            const refineResult = await refineResponse.json();
            
            if (refineResult.choices && refineResult.choices[0]) {
                const refinedPrompt = refineResult.choices[0].message.content;
                console.log(`‚úÖ [Step 5] ChatGPT ƒë√£ refine prompt`);
                
                // Step 6: T·∫°o video Veo3
                console.log(`üé¨ [Step 6] T·∫°o video Veo3...`);
                const serverUrl = 'http://localhost:8888';
                
                const veo3Response = await fetch(`${serverUrl}/api/create-video`, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({
                        input: refinedPrompt,
                        prompt: refinedPrompt
                    })
                });
                
                const veo3Result = await veo3Response.json();
                console.log(`üé¨ [Step 6] Veo3 result:`, veo3Result.success ? '‚úÖ Success' : '‚ùå Failed');
                
                if (veo3Result.success) {
                    console.log(`üé¨ [Step 6] Video Veo3 ƒë√£ ƒë∆∞·ª£c t·∫°o: ${veo3Result.operationName}`);
                    
                    // L∆∞u k·∫øt qu·∫£ ho√†n ch·ªânh
                    const finalResult = {
                        timestamp: new Date().toISOString(),
                        originalVideo: videoPath,
                        startSecond: startSecond,
                        duration: duration,
                        segmentPath: segmentPath,
                        frames: frames,
                        detailedAnalysis: detailedAnalysis,
                        timeline: timeline,
                        refinedPrompt: refinedPrompt,
                        veo3Operation: veo3Result.operationName,
                        veo3Status: veo3Result.videoStatus,
                        outputDir: outputDir
                    };
                    
                    const resultPath = path.join(outputDir, 'veo3-complete-result.json');
                    fs.writeFileSync(resultPath, JSON.stringify(finalResult, null, 2));
                    
                    console.log(`‚úÖ [Step 6] ƒê√£ l∆∞u k·∫øt qu·∫£ v√†o: ${resultPath}`);
                    
                    return {
                        success: true,
                        result: finalResult
                    };
                    
                } else {
                    throw new Error(`T·∫°o video Veo3 th·∫•t b·∫°i: ${veo3Result.message}`);
                }
                
            } else {
                throw new Error('ChatGPT refine kh√¥ng tr·∫£ v·ªÅ k·∫øt qu·∫£ h·ª£p l·ªá');
            }
            
        } else {
            throw new Error('ChatGPT timeline kh√¥ng tr·∫£ v·ªÅ k·∫øt qu·∫£ h·ª£p l·ªá');
        }
        
    } catch (error) {
        console.error(`‚ùå [veo3CompleteWorkflow] L·ªói:`, error.message);
        return {
            success: false,
            error: error.message
        };
    }
}

/**
 * API endpoint cho workflow ho√†n ch·ªânh
 */
async function veo3CompleteWorkflowAPI(req, res) {
    try {
        console.log(`üé¨ [veo3CompleteWorkflowAPI] API workflow ho√†n ch·ªânh ƒë∆∞·ª£c g·ªçi`);
        
        const { videoPath, startSecond, duration, frameInterval, maxFrames, outputDir, themeContext } = req.body;
        
        if (!videoPath) {
            return res.status(400).json({
                success: false,
                message: 'Thi·∫øu videoPath'
            });
        }
        
        const result = await veo3CompleteWorkflow(videoPath, {
            startSecond,
            duration,
            frameInterval,
            maxFrames,
            outputDir,
            themeContext
        });
        
        if (result.success) {
            return res.json({
                success: true,
                message: `ƒê√£ ho√†n th√†nh workflow ho√†n ch·ªânh`,
                result: result.result
            });
        } else {
            return res.status(500).json({
                success: false,
                message: result.error
            });
        }
        
    } catch (error) {
        console.error(`‚ùå [veo3CompleteWorkflowAPI] L·ªói:`, error.message);
        return res.status(500).json({
            success: false,
            message: error.message
        });
    }
}

module.exports = {
    veo3CompleteWorkflow,
    veo3CompleteWorkflowAPI
};
