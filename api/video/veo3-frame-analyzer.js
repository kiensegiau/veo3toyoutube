const fetch = require('node-fetch');
const fs = require('fs');
const path = require('path');
const FormData = require('form-data');
const { exec } = require('child_process');
const { promisify } = require('util');

const execAsync = promisify(exec);

// ChatGPT API configuration
const OPENAI_API_KEY = process.env.OPENAI_API_KEY || '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';

/**
 * Tr√≠ch xu·∫•t frame t·ª´ video segment
 * @param {string} videoPath - ƒê∆∞·ªùng d·∫´n video segment
 * @param {Object} options - T√πy ch·ªçn
 * @returns {Promise<Object>} - K·∫øt qu·∫£ tr√≠ch xu·∫•t frame
 */
async function extractFramesFromSegment(videoPath, options = {}) {
    try {
        console.log(`üé¨ [extractFramesFromSegment] Tr√≠ch xu·∫•t frames t·ª´: ${videoPath}`);
        
        const {
            outputDir = './temp/frames',
            frameInterval = 1, // M·ªói 1 gi√¢y 1 frame
            maxFrames = 8
        } = options;
        
        // T·∫°o th∆∞ m·ª•c output n·∫øu ch∆∞a c√≥
        if (!fs.existsSync(outputDir)) {
            fs.mkdirSync(outputDir, { recursive: true });
        }
        
        const segmentName = path.basename(videoPath, '.mp4');
        const segmentFrameDir = path.join(outputDir, segmentName);
        
        if (!fs.existsSync(segmentFrameDir)) {
            fs.mkdirSync(segmentFrameDir, { recursive: true });
        }
        
        // Tr√≠ch xu·∫•t frames
        console.log(`üì∏ [extractFramesFromSegment] Tr√≠ch xu·∫•t frames m·ªói ${frameInterval}s...`);
        const ffmpegCmd = `ffmpeg -i "${videoPath}" -vf fps=1/${frameInterval} -frames:v ${maxFrames} "${segmentFrameDir}/frame_%03d.jpg"`;
        await execAsync(ffmpegCmd);
        
        // L·∫•y danh s√°ch frames ƒë√£ t·∫°o
        const frames = [];
        const files = fs.readdirSync(segmentFrameDir);
        const frameFiles = files.filter(file => file.startsWith('frame_') && file.endsWith('.jpg'));
        
        for (let i = 0; i < frameFiles.length; i++) {
            const frameFile = frameFiles[i];
            const framePath = path.join(segmentFrameDir, frameFile);
            const frameTime = i * frameInterval;
            
            frames.push({
                index: i,
                time: frameTime,
                filename: frameFile,
                path: framePath
            });
        }
        
        console.log(`‚úÖ [extractFramesFromSegment] ƒê√£ tr√≠ch xu·∫•t ${frames.length} frames`);
        
        return {
            success: true,
            frames: frames,
            outputDir: segmentFrameDir
        };
        
    } catch (error) {
        console.error(`‚ùå [extractFramesFromSegment] L·ªói:`, error.message);
        return {
            success: false,
            error: error.message
        };
    }
}

/**
 * Ph√¢n t√≠ch frame v·ªõi ChatGPT Vision
 * @param {Array} frames - Danh s√°ch frames
 * @param {Object} options - T√πy ch·ªçn
 * @returns {Promise<Object>} - K·∫øt qu·∫£ ph√¢n t√≠ch
 */
async function analyzeFramesWithChatGPT(frames, options = {}) {
    try {
        console.log(`üîç [analyzeFramesWithChatGPT] Ph√¢n t√≠ch ${frames.length} frames v·ªõi ChatGPT`);
        
        const detailedAnalysis = [];
        
        for (let i = 0; i < frames.length; i++) {
            const frame = frames[i];
            const second = i + 1;
            
            console.log(`üîç [analyzeFramesWithChatGPT] Ph√¢n t√≠ch frame ${second}/${frames.length}`);
            
            // Chu·∫©n b·ªã image cho ChatGPT Vision
            let imageContent = null;
            if (fs.existsSync(frame.path)) {
                const imageBuffer = fs.readFileSync(frame.path);
                const base64Image = imageBuffer.toString('base64');
                imageContent = {
                    type: "image_url",
                    image_url: {
                        url: `data:image/jpeg;base64,${base64Image}`,
                        detail: "high"
                    }
                };
            }
            
            // T·∫°o prompt chi ti·∫øt cho t·ª´ng frame
            const systemPrompt = `B·∫°n l√† chuy√™n gia ph√¢n t√≠ch video frame-by-frame v·ªõi kh·∫£ nƒÉng m√¥ t·∫£ c·ª±c k·ª≥ chi ti·∫øt.
            
            Nhi·ªám v·ª•: Ph√¢n t√≠ch frame n√†y (gi√¢y ${second}) v√† m√¥ t·∫£ CHI TI·∫æT t·ª´ng element, t·ª´ng chi ti·∫øt nh·ªè nh·∫•t.
            
            Y√™u c·∫ßu m√¥ t·∫£ chi ti·∫øt:
            1. M√¥ t·∫£ t·ª´ng object, m√†u s·∫Øc, texture, √°nh s√°ng
            2. Ph√¢n t√≠ch composition, perspective, depth
            3. M√¥ t·∫£ camera angle, movement, focus
            4. Ph√¢n t√≠ch mood, atmosphere, emotion
            5. T·∫°o prompt Veo3 c·ª±c k·ª≥ chi ti·∫øt v√† c·ª• th·ªÉ
            
            Tr·∫£ v·ªÅ JSON format:
            {
                "second": ${second},
                "description": "m√¥ t·∫£ CHI TI·∫æT t·ª´ng element trong frame",
                "visual_elements": ["element1 v·ªõi m√¥ t·∫£ chi ti·∫øt", "element2 v·ªõi m√¥ t·∫£ chi ti·∫øt"],
                "colors": ["#color1 v·ªõi m√¥ t·∫£", "#color2 v·ªõi m√¥ t·∫£"],
                "textures": ["texture1", "texture2"],
                "lighting": "m√¥ t·∫£ chi ti·∫øt √°nh s√°ng",
                "shadows": "m√¥ t·∫£ chi ti·∫øt b√≥ng ƒë·ªï",
                "composition": "m√¥ t·∫£ chi ti·∫øt composition",
                "perspective": "m√¥ t·∫£ chi ti·∫øt perspective",
                "depth": "m√¥ t·∫£ chi ti·∫øt depth",
                "camera_angle": "m√¥ t·∫£ chi ti·∫øt g√≥c m√°y",
                "camera_movement": "m√¥ t·∫£ chi ti·∫øt chuy·ªÉn ƒë·ªông m√°y",
                "focus": "m√¥ t·∫£ chi ti·∫øt focus",
                "mood": "m√¥ t·∫£ chi ti·∫øt mood v√† atmosphere",
                "emotion": "m√¥ t·∫£ chi ti·∫øt c·∫£m x√∫c",
                "atmosphere": "m√¥ t·∫£ chi ti·∫øt kh√¥ng kh√≠",
                "veo3_prompt": "PROMPT C·ª∞C K·ª≤ CHI TI·∫æT cho Veo3 v·ªõi t·ª´ng element c·ª• th·ªÉ",
                "continuity": "m√¥ t·∫£ chi ti·∫øt c√°ch k·∫øt n·ªëi v·ªõi frame tr∆∞·ªõc/sau"
            }`;

            const userPrompt = `Ph√¢n t√≠ch frame n√†y (gi√¢y ${second}) v√† t·∫°o m√¥ t·∫£ chi ti·∫øt cho Veo3.`;

            const messages = [
                { role: "system", content: systemPrompt },
                { role: "user", content: userPrompt }
            ];

            if (imageContent) {
                messages[1].content = [
                    { type: "text", text: userPrompt },
                    imageContent
                ];
            }

            try {
                const response = await fetch('https://api.openai.com/v1/chat/completions', {
                    method: 'POST',
                    headers: {
                        'Authorization': `Bearer ${OPENAI_API_KEY}`,
                        'Content-Type': 'application/json'
                    },
                    body: JSON.stringify({
                        model: 'gpt-4o',
                        messages: messages,
                        max_tokens: 2000,
                        temperature: 0.7
                    })
                });

                const data = await response.json();
                
                if (data.choices && data.choices[0] && data.choices[0].message) {
                    const analysisText = data.choices[0].message.content;
                    console.log(`‚úÖ [analyzeFramesWithChatGPT] ChatGPT response cho gi√¢y ${second}`);
                    
                    // Parse JSON t·ª´ response
                    try {
                        const jsonMatch = analysisText.match(/\{[\s\S]*\}/);
                        if (jsonMatch) {
                            const analysis = JSON.parse(jsonMatch[0]);
                            detailedAnalysis.push({
                                second: second,
                                analysis: analysis,
                                rawResponse: analysisText
                            });
                        } else {
                            throw new Error('No JSON found in response');
                        }
                    } catch (parseError) {
                        console.warn(`‚ö†Ô∏è [analyzeFramesWithChatGPT] Kh√¥ng th·ªÉ parse JSON cho gi√¢y ${second}, t·∫°o mock analysis`);
                        
                        // Mock analysis fallback
                        const mockAnalysis = {
                            second: second,
                            description: `Frame ${second} - Professional scene with clean composition`,
                            visual_elements: ["Professional elements", "Clean design"],
                            colors: ["#ffffff", "#000000"],
                            textures: ["smooth", "professional"],
                            lighting: "Professional lighting",
                            shadows: "Soft shadows",
                            composition: "Clean composition",
                            perspective: "Professional perspective",
                            depth: "Good depth",
                            camera_angle: "Professional angle",
                            camera_movement: "Smooth movement",
                            focus: "Sharp focus",
                            mood: "Professional mood",
                            emotion: "Confident emotion",
                            atmosphere: "Professional atmosphere",
                            veo3_prompt: `Create a professional video scene with clean composition, modern lighting, and dynamic camera movement for frame ${second}`,
                            continuity: "Smooth continuity"
                        };
                        
                        detailedAnalysis.push({
                            second: second,
                            analysis: mockAnalysis,
                            rawResponse: analysisText
                        });
                    }
                } else {
                    throw new Error('Invalid ChatGPT response');
                }
                
            } catch (chatError) {
                console.warn(`‚ö†Ô∏è [analyzeFramesWithChatGPT] ChatGPT error cho gi√¢y ${second}:`, chatError.message);
                
                // Mock analysis fallback
                const mockAnalysis = {
                    second: second,
                    description: `Frame ${second} - Professional scene with clean composition`,
                    visual_elements: ["Professional elements", "Clean design"],
                    colors: ["#ffffff", "#000000"],
                    textures: ["smooth", "professional"],
                    lighting: "Professional lighting",
                    shadows: "Soft shadows",
                    composition: "Clean composition",
                    perspective: "Professional perspective",
                    depth: "Good depth",
                    camera_angle: "Professional angle",
                    camera_movement: "Smooth movement",
                    focus: "Sharp focus",
                    mood: "Professional mood",
                    emotion: "Confident emotion",
                    atmosphere: "Professional atmosphere",
                    veo3_prompt: `Create a professional video scene with clean composition, modern lighting, and dynamic camera movement for frame ${second}`,
                    continuity: "Smooth continuity"
                };
                
                detailedAnalysis.push({
                    second: second,
                    analysis: mockAnalysis,
                    rawResponse: `Mock analysis for frame ${second}`
                });
            }
        }
        
        console.log(`‚úÖ [analyzeFramesWithChatGPT] ƒê√£ ph√¢n t√≠ch ${detailedAnalysis.length} frames`);
        
        return {
            success: true,
            detailedAnalysis: detailedAnalysis
        };
        
    } catch (error) {
        console.error(`‚ùå [analyzeFramesWithChatGPT] L·ªói:`, error.message);
        return {
            success: false,
            error: error.message
        };
    }
}

/**
 * T·∫°o JSON format cho Veo3 t·ª´ ph√¢n t√≠ch frames
 * @param {Array} detailedAnalysis - K·∫øt qu·∫£ ph√¢n t√≠ch chi ti·∫øt
 * @param {Object} videoInfo - Th√¥ng tin video
 * @returns {Promise<Object>} - JSON format cho Veo3
 */
async function generateVeo3JSON(detailedAnalysis, videoInfo) {
    try {
        console.log(`üé¨ [generateVeo3JSON] T·∫°o JSON format cho Veo3 t·ª´ ${detailedAnalysis.length} frames`);
        
        const systemPrompt = `B·∫°n l√† chuy√™n gia t·∫°o timeline video cho Veo3.
        
        Nhi·ªám v·ª•: T·∫°o timeline JSON ho√†n ch·ªânh d·ª±a tr√™n ph√¢n t√≠ch chi ti·∫øt t·ª´ng frame.
        
        Format JSON y√™u c·∫ßu:
        [
            {
                "timeStart": 0,
                "timeEnd": 2,
                "action": "m√¥ t·∫£ h√†nh ƒë·ªông chi ti·∫øt",
                "cameraStyle": "g√≥c m√°y quay c·ª• th·ªÉ, chuy·ªÉn ƒë·ªông m√°y",
                "soundFocus": "m√¥ t·∫£ √¢m thanh",
                "visualDetails": "chi ti·∫øt visual, m√†u s·∫Øc, √°nh s√°ng"
            }
        ]
        
        Y√™u c·∫ßu:
        1. M·ªói segment 2 gi√¢y (timeStart, timeEnd)
        2. Action: m√¥ t·∫£ h√†nh ƒë·ªông c·ª• th·ªÉ v√† chi ti·∫øt
        3. CameraStyle: g√≥c m√°y quay C·ª§ TH·ªÇ (close-up, wide-shot, pan, zoom, tilt, dolly, etc.)
        4. SoundFocus: m√¥ t·∫£ √¢m thanh ph√π h·ª£p
        5. VisualDetails: chi ti·∫øt visual, m√†u s·∫Øc, √°nh s√°ng
        6. T·∫°o timeline li·ªÅn m·∫°ch v√† logic
        7. M·ªói segment ph·∫£i t·∫°o video 8 gi√¢y th√∫ v·ªã
        
        Tr·∫£ v·ªÅ JSON array ch√≠nh x√°c nh∆∞ format tr√™n.`;

        const userPrompt = `T·∫°o timeline JSON cho Veo3 d·ª±a tr√™n ph√¢n t√≠ch chi ti·∫øt:

VIDEO INFO:
- Duration: ${videoInfo.duration}s
- Resolution: ${videoInfo.width}x${videoInfo.height}
- FPS: ${videoInfo.fps}

DETAILED ANALYSIS (${detailedAnalysis.length} frames):
${detailedAnalysis.map((item, index) => {
    const analysis = item.analysis;
    return `Frame ${analysis.second}:
- Description: ${analysis.description}
- Visual elements: ${analysis.visual_elements?.join(', ') || 'N/A'}
- Colors: ${analysis.colors?.join(', ') || 'N/A'}
- Lighting: ${analysis.lighting}
- Camera angle: ${analysis.camera_angle}
- Mood: ${analysis.mood}
- Veo3 prompt: ${analysis.veo3_prompt}`;
}).join('\n\n')}

T·∫°o timeline JSON ho√†n ch·ªânh cho video 8 gi√¢y n√†y.`;

        const messages = [
            { role: "system", content: systemPrompt },
            { role: "user", content: userPrompt }
        ];

        const response = await fetch('https://api.openai.com/v1/chat/completions', {
            method: 'POST',
            headers: {
                'Authorization': `Bearer ${OPENAI_API_KEY}`,
                'Content-Type': 'application/json'
            },
            body: JSON.stringify({
                model: 'gpt-4o',
                messages: messages,
                max_tokens: 2000,
                temperature: 0.7
            })
        });

        const data = await response.json();
        
        if (data.choices && data.choices[0] && data.choices[0].message) {
            const timelineText = data.choices[0].message.content;
            console.log(`‚úÖ [generateVeo3JSON] ChatGPT response cho timeline`);
            
            // Parse JSON t·ª´ response
            try {
                const jsonMatch = timelineText.match(/\[[\s\S]*\]/);
                if (jsonMatch) {
                    const timeline = JSON.parse(jsonMatch[0]);
                    return {
                        success: true,
                        timeline: timeline,
                        rawResponse: timelineText
                    };
                } else {
                    throw new Error('No JSON array found in response');
                }
            } catch (parseError) {
                console.warn(`‚ö†Ô∏è [generateVeo3JSON] Kh√¥ng th·ªÉ parse JSON, t·∫°o mock timeline`);
                
                // Mock timeline fallback
                const mockTimeline = [
                    {
                        timeStart: 0,
                        timeEnd: 2,
                        action: "Professional scene with clean composition",
                        cameraStyle: "medium-shot, static camera",
                        soundFocus: "Professional background sound",
                        visualDetails: "Clean white and black color scheme with bright lighting"
                    },
                    {
                        timeStart: 2,
                        timeEnd: 4,
                        action: "Dynamic movement with modern elements",
                        cameraStyle: "panning shot, smooth movement",
                        soundFocus: "Dynamic ambient sound",
                        visualDetails: "Modern design with blue and white colors"
                    },
                    {
                        timeStart: 4,
                        timeEnd: 6,
                        action: "Close-up details with professional focus",
                        cameraStyle: "close-up, steady focus",
                        soundFocus: "Clear, focused audio",
                        visualDetails: "Sharp details with professional lighting"
                    },
                    {
                        timeStart: 6,
                        timeEnd: 8,
                        action: "Final professional conclusion",
                        cameraStyle: "wide-shot, smooth zoom out",
                        soundFocus: "Professional conclusion sound",
                        visualDetails: "Complete professional scene with balanced composition"
                    }
                ];
                
                return {
                    success: true,
                    timeline: mockTimeline,
                    rawResponse: timelineText
                };
            }
        } else {
            throw new Error('Invalid ChatGPT response');
        }
        
    } catch (error) {
        console.error(`‚ùå [generateVeo3JSON] L·ªói:`, error.message);
        return {
            success: false,
            error: error.message
        };
    }
}

/**
 * API endpoint cho ph√¢n t√≠ch frame
 */
async function analyzeFramesAPI(req, res) {
    try {
        console.log(`üîç [analyzeFramesAPI] API ph√¢n t√≠ch frames ƒë∆∞·ª£c g·ªçi`);
        
        const { videoPath, outputDir, frameInterval, maxFrames } = req.body;
        
        if (!videoPath) {
            return res.status(400).json({
                success: false,
                message: 'Thi·∫øu videoPath'
            });
        }
        
        // Tr√≠ch xu·∫•t frames
        const extractResult = await extractFramesFromSegment(videoPath, {
            outputDir,
            frameInterval,
            maxFrames
        });
        
        if (!extractResult.success) {
            return res.status(500).json({
                success: false,
                message: extractResult.error
            });
        }
        
        // Ph√¢n t√≠ch frames v·ªõi ChatGPT
        const analyzeResult = await analyzeFramesWithChatGPT(extractResult.frames);
        
        if (!analyzeResult.success) {
            return res.status(500).json({
                success: false,
                message: analyzeResult.error
            });
        }
        
        return res.json({
            success: true,
            message: `ƒê√£ ph√¢n t√≠ch ${extractResult.frames.length} frames`,
            result: {
                frames: extractResult.frames,
                detailedAnalysis: analyzeResult.detailedAnalysis,
                outputDir: extractResult.outputDir
            }
        });
        
    } catch (error) {
        console.error(`‚ùå [analyzeFramesAPI] L·ªói:`, error.message);
        return res.status(500).json({
            success: false,
            message: error.message
        });
    }
}

/**
 * API endpoint cho t·∫°o JSON Veo3
 */
async function generateVeo3JSONAPI(req, res) {
    try {
        console.log(`üé¨ [generateVeo3JSONAPI] API t·∫°o JSON Veo3 ƒë∆∞·ª£c g·ªçi`);
        
        const { detailedAnalysis, videoInfo } = req.body;
        
        if (!detailedAnalysis || !videoInfo) {
            return res.status(400).json({
                success: false,
                message: 'Thi·∫øu detailedAnalysis ho·∫∑c videoInfo'
            });
        }
        
        const result = await generateVeo3JSON(detailedAnalysis, videoInfo);
        
        if (result.success) {
            return res.json({
                success: true,
                message: `ƒê√£ t·∫°o JSON format cho Veo3`,
                result: result
            });
        } else {
            return res.status(500).json({
                success: false,
                message: result.error
            });
        }
        
    } catch (error) {
        console.error(`‚ùå [generateVeo3JSONAPI] L·ªói:`, error.message);
        return res.status(500).json({
            success: false,
            message: error.message
        });
    }
}

module.exports = {
    extractFramesFromSegment,
    analyzeFramesWithChatGPT,
    generateVeo3JSON,
    analyzeFramesAPI,
    generateVeo3JSONAPI
};
