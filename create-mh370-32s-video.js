const fetch = require('node-fetch');
const https = require('https');
const fs = require('fs');
const path = require('path');
const { exec } = require('child_process');
const { promisify } = require('util');

const execAsync = promisify(exec);

// ChatGPT API configuration (no hardcoded default)
const OPENAI_API_KEY = process.env.OPENAI_API_KEY || '';
const LABS_COOKIES = (process.env.LABS_COOKIES || '').trim();
const RUN_MODE = (process.env.RUN_MODE || 'default').toLowerCase();
const VEO_PROJECT_ID = (process.env.VEO_PROJECT_ID || '').trim();

// Networking helpers for resilient OpenAI calls
const keepAliveAgent = new https.Agent({ keepAlive: true, maxSockets: 50 });
function sleep(ms){ return new Promise(r=>setTimeout(r, ms)); }
async function fetchOpenAIWithRetry(payload, { maxRetries = 7, baseDelayMs = 1500 } = {}){
    let attempt = 0;
    while (true){
        attempt++;
        const controller = new AbortController();
        const timeout = setTimeout(()=> controller.abort(), 90000); // 90s
        try{
            const resp = await fetch('https://api.openai.com/v1/chat/completions', {
                method: 'POST',
                headers: {
                    'Authorization': `Bearer ${OPENAI_API_KEY}`,
                    'Content-Type': 'application/json'
                },
                body: JSON.stringify(payload),
                agent: keepAliveAgent,
                signal: controller.signal
            });
            clearTimeout(timeout);
            if (resp.ok){ return await resp.json(); }
            const status = resp.status;
            const text = await resp.text().catch(()=> '');
            // Backoff for 429/5xx
            if ((status === 429 || status >= 500) && attempt <= maxRetries){
                const retryAfter = Number(resp.headers.get('retry-after') || 0) * 1000;
                const backoff = retryAfter || Math.min(30000, baseDelayMs * Math.pow(2, attempt-1));
                console.log(`‚ö†Ô∏è  OpenAI HTTP ${status}. Retry in ${Math.round(backoff/1000)}s (attempt ${attempt}/${maxRetries})`);
                await sleep(backoff + Math.floor(Math.random()*400));
                continue;
            }
            throw new Error(`OpenAI HTTP ${status}: ${text}`);
        }catch(err){
            clearTimeout(timeout);
            const msg = String(err && err.message || err);
            const transient = /ECONNRESET|ETIMEDOUT|socket hang up|network|aborted|timeout/i.test(msg);
            if (transient && attempt <= maxRetries){
                const backoff = Math.min(30000, baseDelayMs * Math.pow(2, attempt-1));
                console.log(`‚ö†Ô∏è  OpenAI transient error: ${msg}. Retry in ${Math.round(backoff/1000)}s (attempt ${attempt}/${maxRetries})`);
                await sleep(backoff + Math.floor(Math.random()*400));
                continue;
            }
            throw err;
        }
    }
}

// Video Configuration
const SEGMENT_DURATION = 8; // Each segment duration (seconds)
const BATCH_SIZE = 50; // S·ªë segments m·ªói batch (do gi·ªõi h·∫°n ChatGPT tokens)

// Cache cookie ƒë·ªÉ tr√°nh l·∫•y li√™n t·ª•c
let cachedCookie = null;
let cookieCacheTime = 0;
const COOKIE_CACHE_DURATION = 30 * 60 * 1000; // 30 ph√∫t

/**
 * ƒê·ªçc cookie t·ª´ file labs-cookies.txt
 */
function readCookieFromFile() {
    try {
        const cookieFilePath = path.join(__dirname, 'labs-cookies.txt');

        if (!fs.existsSync(cookieFilePath)) {
            console.log('‚ùå File labs-cookies.txt kh√¥ng t·ªìn t·∫°i');
            return null;
        }

        const content = fs.readFileSync(cookieFilePath, 'utf8');
        const lines = content.split('\n');

        // T√¨m d√≤ng ch·ª©a cookies (b·ªè qua d√≤ng comment)
        for (let i = 0; i < lines.length; i++) {
            const line = lines[i];
            if (line.trim() && !line.startsWith('#')) {
                console.log(`‚úÖ ƒê·ªçc cookie t·ª´ file labs-cookies.txt`);
                return line.trim();
            }
        }

        console.log('‚ùå Kh√¥ng t√¨m th·∫•y cookies trong file');
        return null;
    } catch (error) {
        console.error('‚ùå L·ªói ƒë·ªçc cookie t·ª´ file:', error.message);
        return null;
    }
}

/**
 * L·∫•y cookie t·ª´ cache ho·∫∑c fetch m·ªõi, fallback t·ª´ file txt
 */
async function getCachedOrFreshCookie(serverUrl) {
    const now = Date.now();

    // In VPS mode: never fetch or read file. Use LABS_COOKIES only.
    if (RUN_MODE === 'vps') {
        if (LABS_COOKIES) {
            cachedCookie = LABS_COOKIES;
            cookieCacheTime = now;
            console.log('üç™ [VPS] D√πng Labs cookies t·ª´ ENV (LABS_COOKIES)');
            return cachedCookie;
        }
        console.log('‚ùå [VPS] Thi·∫øu LABS_COOKIES trong env. Kh√¥ng ƒë∆∞·ª£c ph√©p ƒë·ªçc file hay g·ªçi server.');
        return null;
    }

    // N·∫øu c√≥ cache v√† ch∆∞a h·∫øt h·∫°n
    if (cachedCookie && (now - cookieCacheTime) < COOKIE_CACHE_DURATION) {
        console.log(`üç™ S·ª≠ d·ª•ng cached cookie (c√≤n ${Math.floor((COOKIE_CACHE_DURATION - (now - cookieCacheTime)) / 1000 / 60)} ph√∫t)`);
        return cachedCookie;
    }

    // L·∫•y cookie m·ªõi t·ª´ server
    console.log(`üîÑ L·∫•y cookie m·ªõi t·ª´ server...`);
    try {
        const response = await fetch(`${serverUrl}/api/labs/get-cookies`, {
            method: 'GET'
        });

        const result = await response.json();

        if (result.success && result.cookies) {
            cachedCookie = result.cookies;
            cookieCacheTime = now;
            console.log(`‚úÖ ƒê√£ cache cookie m·ªõi t·ª´ server`);
            return cachedCookie;
        } else {
            throw new Error('Kh√¥ng l·∫•y ƒë∆∞·ª£c cookie t·ª´ server');
        }
    } catch (error) {
        console.error(`‚ùå L·ªói l·∫•y cookie t·ª´ server:`, error.message);
        console.log(`üîÑ Th·ª≠ l·∫•y cookie t·ª´ file labs-cookies.txt...`);

        // Fallback (default mode only): ƒê·ªçc cookie t·ª´ file txt
        if (RUN_MODE !== 'vps') {
            const cookieFromFile = readCookieFromFile();
            if (cookieFromFile) {
                cachedCookie = cookieFromFile;
                cookieCacheTime = now;
                console.log(`‚úÖ S·ª≠ d·ª•ng cookie t·ª´ file labs-cookies.txt`);
                return cachedCookie;
            }
        }
        console.error(`‚ùå Kh√¥ng th·ªÉ l·∫•y cookie (server/file b·ªã c·∫•m trong VPS ho·∫∑c kh√¥ng c√≥)`);
        return null;
    }
}

/**
 * T·∫°o video v·ªõi transcript v√† h√¨nh ·∫£nh ƒë·ªìng nh·∫•t
 */
async function createMH370Video32s() {
    try {
        const serverUrl = 'http://localhost:8888';
        // Allow override via env or CLI arg --url="..." or first positional
        const argv = process.argv.slice(2).join(' ');
        const urlFromFlag = (argv.match(/--url\s*=\s*"([^"]+)"/) || argv.match(/--url\s*=\s*'([^']+)'/) || argv.match(/--url\s*=\s*([^\s]+)/) || [])[1];
        const positionalUrl = argv && !argv.includes('--url') ? argv.trim().split(/\s+/)[0] : '';
        const youtubeUrl = process.env.YOUTUBE_URL || urlFromFlag || positionalUrl || 'https://youtu.be/52ru0qDc0LQ?si=zahSVRyDiQy7Jd6H';

        // Extract video ID t·ª´ URL
        const videoIdMatch = youtubeUrl.match(/(?:youtube\.com\/watch\?v=|youtu\.be\/)([^&\n?#]+)/);
        const videoId = videoIdMatch ? videoIdMatch[1] : null;

        if (!videoId) {
            throw new Error('Kh√¥ng th·ªÉ extract video ID t·ª´ URL');
        }

        // Step 0: L·∫•y metadata video (ch·ªâ ƒë·ªÉ l·∫•y title)
        console.log('üìπ [Step 0] L·∫•y metadata video YouTube...');

        let videoTitle = 'Unknown Video';

        try {
            const metadataResponse = await fetch(`${serverUrl}/api/get-video-metadata`, {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({
                    videoId: videoId
                })
            });

            const metadataResult = await metadataResponse.json();
            console.log('üìπ [Step 0] Metadata result:', metadataResult.success ? '‚úÖ Success' : '‚ùå Failed');

            if (metadataResult.success && metadataResult.video) {
                videoTitle = metadataResult.video.title || 'Unknown Video';
                console.log(`üìπ [Step 0] Video: "${videoTitle}"`);
            }
        } catch (error) {
            console.error(`‚ùå [Step 0] L·ªói l·∫•y metadata:`, error.message);
        }

        // Step 1: L·∫•y transcript t·ª´ YouTube
        console.log('üìù [Step 1] L·∫•y transcript t·ª´ YouTube...');
        const transcriptResponse = await fetch(`${serverUrl}/api/get-transcript`, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({
                url: youtubeUrl,
                lang: 'vi'
            })
        });
        
        const transcriptResult = await transcriptResponse.json();
        console.log('üìù [Step 1] Transcript result:', transcriptResult.success ? '‚úÖ Success' : '‚ùå Failed');

        if (!transcriptResult.success) {
            throw new Error(`Kh√¥ng th·ªÉ l·∫•y transcript: ${transcriptResult.message}`);
        }

        // Debug: Xem transcript format
        console.log('üìù [Step 1] Transcript type:', typeof transcriptResult.transcript);
        console.log('üìù [Step 1] Is array:', Array.isArray(transcriptResult.transcript));
        if (transcriptResult.transcript) {
            const preview = typeof transcriptResult.transcript === 'string'
                ? transcriptResult.transcript.substring(0, 200)
                : JSON.stringify(transcriptResult.transcript).substring(0, 200);
            console.log('üìù [Step 1] Transcript preview:', preview + '...');
        }

        // B∆Ø·ªöC 1: Chu·∫©n h√≥a transcript th√†nh vƒÉn b·∫£n d√†i
        let fullText = '';

        if (Array.isArray(transcriptResult.transcript)) {
            // N·∫øu l√† array, gh√©p t·∫•t c·∫£ text l·∫°i
            fullText = transcriptResult.transcript
                .map(item => {
                    if (typeof item === 'string') return item;
                    if (item && item.text) return item.text;
                    return '';
                })
                .join(' ');
        } else if (typeof transcriptResult.transcript === 'object' && transcriptResult.transcript.content) {
            // Transcript l√† object v·ªõi content field
            fullText = transcriptResult.transcript.content;
        } else if (typeof transcriptResult.transcript === 'string') {
            // Transcript l√† string thu·∫ßn
            fullText = transcriptResult.transcript;
        } else {
            throw new Error('Transcript format kh√¥ng h·ª£p l·ªá');
        }

        // Chu·∫©n h√≥a: lo·∫°i b·ªè kho·∫£ng tr·∫Øng th·ª´a, xu·ªëng d√≤ng
        fullText = fullText.replace(/\s+/g, ' ').trim();

        console.log(`üìù [Step 1] Transcript vƒÉn b·∫£n d√†i: ${fullText.length} k√Ω t·ª±`);
        console.log(`üìù [Step 1] Preview: "${fullText.substring(0, 200)}..."`);

        // B∆Ø·ªöC 2: Chia vƒÉn b·∫£n d√†i th√†nh segments 8 gi√¢y
        // ∆Ø·ªõc t√≠nh s·ªë t·ª´ c√≥ th·ªÉ ƒë·ªçc trong 8 gi√¢y (kho·∫£ng 20-25 t·ª´ ti·∫øng Vi·ªát)
        const wordsPerSegment = 25;
        const words = fullText.split(' ');
        const transcriptSegments = [];

        for (let i = 0; i < words.length; i += wordsPerSegment) {
            const segmentWords = words.slice(i, i + wordsPerSegment);
            const segmentText = segmentWords.join(' ');
            const segmentIndex = Math.floor(i / wordsPerSegment);

            transcriptSegments.push({
                index: segmentIndex,
                text: segmentText,
                startTime: segmentIndex * SEGMENT_DURATION,
                endTime: (segmentIndex + 1) * SEGMENT_DURATION,
                duration: SEGMENT_DURATION
            });
        }

        console.log(`üìù [Step 1] ƒê√£ chia th√†nh ${transcriptSegments.length} segments`);

        // T·∫°o transcriptText ƒë·ªÉ d√πng cho ChatGPT
        const transcriptText = transcriptSegments.map(s => s.text).join(' ');

        // T√≠nh to√°n s·ªë segments v√† batches d·ª±a tr√™n transcript
        const TOTAL_SEGMENTS = transcriptSegments.length;
        const NUM_BATCHES = Math.ceil(TOTAL_SEGMENTS / BATCH_SIZE);
        const VIDEO_DURATION = TOTAL_SEGMENTS * SEGMENT_DURATION;

        console.log(`üìù [Step 1] T·ªïng s·ªë segments: ${TOTAL_SEGMENTS} (${SEGMENT_DURATION}s/segment)`);
        console.log(`üìù [Step 1] Chia th√†nh ${NUM_BATCHES} batches (${BATCH_SIZE} segments/batch)`);
        console.log(`üìù [Step 1] T·ªïng th·ªùi gian video: ${VIDEO_DURATION}s (${Math.floor(VIDEO_DURATION / 60)}:${(VIDEO_DURATION % 60).toString().padStart(2, '0')})`);

        const outputDir = `./temp/youtube-${TOTAL_SEGMENTS}segments-video`;

        // T·∫°o th∆∞ m·ª•c output
        if (!fs.existsSync(outputDir)) {
            fs.mkdirSync(outputDir, { recursive: true });
        }

        // Step 2: X·ª≠ l√Ω t·ª´ng batch
        console.log(`ü§ñ [Step 2] X·ª≠ l√Ω ${NUM_BATCHES} batches...`);

        let allSegments = [];
        let overallTheme = '';
        let colorScheme = '';
        let visualStyle = '';

        // X·ª≠ l√Ω t·ª´ng batch
        for (let batchIndex = 0; batchIndex < NUM_BATCHES; batchIndex++) {
            const startSegment = batchIndex * BATCH_SIZE;
            const endSegment = Math.min((batchIndex + 1) * BATCH_SIZE, TOTAL_SEGMENTS);
            const batchSegmentCount = endSegment - startSegment;
            const batchStartTime = startSegment * SEGMENT_DURATION;
            const batchEndTime = endSegment * SEGMENT_DURATION;

            // L·∫•y transcript cho batch n√†y
            const batchTranscriptSegments = transcriptSegments.slice(startSegment, endSegment);

            console.log(`\nüîÑ [Batch ${batchIndex + 1}/${NUM_BATCHES}] X·ª≠ l√Ω segments ${startSegment + 1}-${endSegment} (${batchStartTime}s-${batchEndTime}s, ${batchSegmentCount} segments)...`);

        // Step 2: ChatGPT ph√¢n t√≠ch v√† t·∫°o prompt cho batch n√†y
        console.log(`ü§ñ [Batch ${batchIndex + 1}] ChatGPT t·∫°o prompt cho ${batchSegmentCount} segments...`);
        
        const chatGPTResult = await fetchOpenAIWithRetry({
            model: 'gpt-4o-mini',
            messages: [
                    { 
                        role: "system", 
                        content: `B·∫°n l√† chuy√™n gia t·∫°o prompt video cho Veo3 v·ªõi kh·∫£ nƒÉng visual h√≥a n·ªôi dung transcript CH√çNH X√ÅC.

‚ö†Ô∏è QUAN TR·ªåNG TUY·ªÜT ƒê·ªêI:
1. üéØ CH·ªà t·∫°o visual D·ª∞A TR√äN n·ªôi dung C√ì TRONG transcript - KH√îNG s√°ng t·∫°o th√™m
2. üìñ ƒê·ªåC K·ª∏ transcript, hi·ªÉu ƒë√∫ng n·ªôi dung, r·ªìi m·ªõi visual h√≥a
3. ‚úÖ M·ªói segment PH·∫¢I kh·ªõp v·ªõi 1 ph·∫ßn C·ª§ TH·ªÇ trong transcript
4. ‚ùå KH√îNG t·∫°o c·∫£nh kh√¥ng li√™n quan ƒë·∫øn transcript
5. ‚ùå KH√îNG c√≥ text/ch·ªØ/caption trong video (Veo3 kh√¥ng h·ªó tr·ª£)

Nhi·ªám v·ª•: Ph√¢n t√≠ch transcript th√†nh ${batchSegmentCount} segments (${SEGMENT_DURATION}s/segment, t·ª´ ${batchStartTime}s ƒë·∫øn ${batchEndTime}s):
1. ƒê√öNG N·ªòI DUNG: M·ªói prompt ph·∫£i visual h√≥a ƒê√öNG 1 ph·∫ßn c·ª• th·ªÉ trong transcript
2. M√ÄU S·∫ÆC ƒê·ªíNG NH·∫§T: Ch·ªçn b·∫£ng m√†u ph√π h·ª£p v·ªõi ch·ªß ƒë·ªÅ th·ª±c t·∫ø c·ªßa transcript
3. PHONG C√ÅCH PH√ô H·ª¢P: Documentary/cinematic/artistic t√πy n·ªôi dung transcript
4. LI√äN K·∫æT M∆Ø·ª¢T: C√°c segments chuy·ªÉn ti·∫øp t·ª± nhi√™n theo d√≤ng ch·∫£y transcript
5. CHI TI·∫æT C·ª§ TH·ªÇ: Visual c·ª• th·ªÉ t·ª´ transcript - KH√îNG s√°ng t·∫°o
6. C√ÇU CHUY·ªÜN ƒê√öNG: Theo ƒë√∫ng logic v√† th·ª© t·ª± c·ªßa transcript

Tr·∫£ v·ªÅ JSON format v·ªõi ${batchSegmentCount} segments LI√äN T·ª§C (t·ª´ ${batchStartTime}s ƒë·∫øn ${batchEndTime}s):
{
    "overallTheme": "Ch·ªß ƒë·ªÅ CH√çNH duy nh·∫•t xuy√™n su·ªët video (d·ª±a tr√™n transcript)",
    "colorScheme": "B·∫£ng m√†u NH·∫§T QU√ÅN cho to√†n b·ªô video",
    "visualStyle": "Phong c√°ch ƒê·ªíNG NH·∫§T (documentary/cinematic/artistic)",
    "segments": [
        {
            "timeRange": "${batchStartTime}-${batchStartTime + SEGMENT_DURATION}s",
            "focus": "Ph·∫ßn ƒë·∫ßu c·ªßa batch (t·ª´ transcript)",
            "prompt": "Visual m·ªü ƒë·∫ßu batch - ƒë√∫ng n·ªôi dung transcript, C√ì LI√äN K·∫æT v·ªõi segment sau"
        },
        {
            "timeRange": "${batchStartTime + SEGMENT_DURATION}-${batchStartTime + SEGMENT_DURATION * 2}s",
            "focus": "Ti·∫øp t·ª•c ch·ªß ƒë·ªÅ (t·ª´ transcript)",
            "prompt": "Visual ti·∫øp n·ªëi segment tr∆∞·ªõc - c√πng B·ªêI C·∫¢NH, LI√äN K·∫æT v·ªõi segment tr∆∞·ªõc/sau"
        },
        ... (t·ªïng ${batchSegmentCount} segments - T·∫§T C·∫¢ PH·∫¢I C√ôNG CH·ª¶ ƒê·ªÄ/B·ªêI C·∫¢NH)
        {
            "timeRange": "${batchEndTime - SEGMENT_DURATION}-${batchEndTime}s",
            "focus": "K·∫øt th√∫c batch (t·ª´ transcript)",
            "prompt": "Visual k·∫øt th√∫c batch - LI√äN K·∫æT v·ªõi segment tr∆∞·ªõc, ƒë√∫ng n·ªôi dung transcript"
        }
    ]
}

‚ö†Ô∏è L∆ØU √ù: T·∫•t c·∫£ segments PH·∫¢I c√πng overallTheme v√† visualStyle, KH√îNG nh·∫£y sang ch·ªß ƒë·ªÅ kh√°c!` 
                    },
                    {
                        role: "user",
                        content: `üéØ ƒê·ªåC K·ª∏ transcript v√† t·∫°o ${batchSegmentCount} prompts ƒê√öNG N·ªòI DUNG cho batch ${batchIndex + 1}/${NUM_BATCHES} (${batchStartTime}s-${batchEndTime}s):

üìÑ TRANSCRIPT CHO BATCH N√ÄY (${batchSegmentCount} segments):
${batchTranscriptSegments.map((seg, idx) => `Segment ${startSegment + idx + 1} (${seg.startTime}s-${seg.endTime}s): "${seg.text}"`).join('\n')}

üìÑ TO√ÄN B·ªò TRANSCRIPT (ƒë·ªÉ hi·ªÉu context):
${transcriptText}

üîç B∆Ø·ªöC 1 - ƒê·ªåC V√Ä PH√ÇN T√çCH:
- ƒê·ªçc K·ª∏ TO√ÄN B·ªò transcript t·ª´ ƒë·∫ßu ƒë·∫øn cu·ªëi
- X√°c ƒë·ªãnh CH·ª¶ ƒê·ªÄ CH√çNH, B·ªêI C·∫¢NH, v√† LU·ªíNG C√ÇU CHUY·ªÜN
- N·∫Øm r√µ c√°c s·ª± ki·ªán, kh√°i ni·ªám, h√†nh ƒë·ªông ƒë∆∞·ª£c ƒë·ªÅ c·∫≠p
- X√°c ƒë·ªãnh M√îI TR∆Ø·ªúNG/B·ªêI C·∫¢NH chung xuy√™n su·ªët video

üé¨ B∆Ø·ªöC 2 - T·∫†O ${batchSegmentCount} PROMPTS LI√äN T·ª§C CHO BATCH N√ÄY:
1. CH·ª¶ ƒê·ªÄ & B·ªêI C·∫¢NH XUY√äN SU·ªêT:
   - T·∫•t c·∫£ ${batchSegmentCount} segments PH·∫¢I c√πng 1 ch·ªß ƒë·ªÅ/b·ªëi c·∫£nh ch√≠nh${batchIndex > 0 ? ` (ti·∫øp n·ªëi t·ª´ batch tr∆∞·ªõc)` : ''}
   - KH√îNG nh·∫£y sang ch·ªß ƒë·ªÅ/b·ªëi c·∫£nh kh√°c kh√¥ng li√™n quan
   - Visual ph·∫£i C√ì S·ª∞ LI√äN K·∫æT gi·ªØa c√°c segments
   
2. ƒê√öNG N·ªòI DUNG TRANSCRIPT:
   - M·ªói segment = visual h√≥a 1 ph·∫ßn C·ª§ TH·ªÇ trong transcript
   - Theo ƒë√∫ng TH·ª® T·ª∞ v√† LOGIC c·ªßa transcript
   - KH√îNG s√°ng t·∫°o th√™m c·∫£nh kh√¥ng ƒë∆∞·ª£c nh·∫Øc ƒë·∫øn

üìã V√ç D·ª§ V·ªÄ T√çNH LI√äN T·ª§C:
‚úÖ ƒê√öNG - Video xuy√™n su·ªët v·ªÅ "du l·ªãch bi·ªÉn":
   Seg 1: B√£i bi·ªÉn bu·ªïi s√°ng ‚Üí Seg 2: L·∫∑n bi·ªÉn ‚Üí Seg 3: Ng·∫Øm san h√¥ ‚Üí Seg 4: Ho√†ng h√¥n bi·ªÉn
   ‚Üí T·∫•t c·∫£ c√πng B·ªêI C·∫¢NH BI·ªÇN, li√™n k·∫øt m∆∞·ª£t m√†

‚ùå SAI - Nh·∫£y c√≥c kh√¥ng li√™n quan:
   Seg 1: B√£i bi·ªÉn ‚Üí Seg 2: N√∫i tuy·∫øt ‚Üí Seg 3: Th√†nh ph·ªë ‚Üí Seg 4: Sa m·∫°c
   ‚Üí Nh·∫£y lung tung, kh√¥ng c√≥ s·ª± li√™n k·∫øt

üìã V√ç D·ª§ ƒê√öNG SAI V·ªöI TRANSCRIPT:
‚úÖ ƒê√öNG: Transcript n√≥i "m√°y bay c·∫•t c√°nh" ‚Üí Prompt: "M√°y bay Boeing c·∫•t c√°nh t·ª´ s√¢n bay"
‚úÖ ƒê√öNG: Transcript n√≥i "radar m·∫•t t√≠n hi·ªáu" ‚Üí Prompt: "M√†n h√¨nh radar v·ªõi t√≠n hi·ªáu bi·∫øn m·∫•t"
‚ùå SAI: Transcript v·ªÅ "n·∫•u ƒÉn" nh∆∞ng segment 5 l·∫°i vi·∫øt v·ªÅ "ƒë√° b√≥ng" (kh√¥ng li√™n quan)
‚ùå SAI: T·ª± th√™m c·∫£nh kh√¥ng c√≥ trong transcript

‚ö†Ô∏è Y√äU C·∫¶U VISUAL:
‚ùå KH√îNG c√≥ text/ch·ªØ/caption/subtitle/title trong video
‚ùå KH√îNG c√≥ graphic text/watermark/logo
‚úÖ CH·ªà visual thu·∫ßn: objects, scenes, actions, movements, atmosphere

üéØ KI·ªÇM TRA CU·ªêI C√ôNG TR∆Ø·ªöC KHI TR·∫¢ V·ªÄ:
1. T·∫•t c·∫£ ${batchSegmentCount} segments c√≥ c√πng CH·ª¶ ƒê·ªÄ/B·ªêI C·∫¢NH ch√≠nh kh√¥ng?
2. C√≥ segment n√†o nh·∫£y sang ch·ªß ƒë·ªÅ kh√°c kh√¥ng li√™n quan kh√¥ng?
3. Visual c√≥ th·ªÉ chuy·ªÉn ti·∫øp m∆∞·ª£t m√† t·ª´ segment n√†y sang segment kh√°c kh√¥ng?
4. T·∫•t c·∫£ ƒë·ªÅu d·ª±a tr√™n N·ªòI DUNG C√ì TRONG transcript ch·ª©?
${batchIndex > 0 ? `5. Batch n√†y c√≥ LI√äN K·∫æT m∆∞·ª£t m√† v·ªõi batch tr∆∞·ªõc (ch·ªß ƒë·ªÅ: ${overallTheme}) kh√¥ng?` : ''}

üí° M·ª§C TI√äU: ${batchSegmentCount} segments gh√©p l·∫°i ph·∫£i nh∆∞ 1 video LI·ªÄN M·∫†CH, XUY√äN SU·ªêT 1 CH·ª¶ ƒê·ªÄ!`
                    }
                ],
                max_tokens: Math.min(16384, batchSegmentCount * 200), // ƒê·ªông d·ª±a tr√™n s·ªë segments trong batch
                temperature: 0.3 // Th·∫•p ƒë·ªÉ ch√≠nh x√°c, √≠t s√°ng t·∫°o, t·∫≠p trung v√†o transcript
        });
        console.log(`ü§ñ [Batch ${batchIndex + 1}] ChatGPT result:`, chatGPTResult.choices ? '‚úÖ Success' : '‚ùå Failed');

        if (!chatGPTResult.choices) {
            throw new Error('ChatGPT kh√¥ng tr·∫£ v·ªÅ k·∫øt qu·∫£');
        }

        const analysisText = chatGPTResult.choices[0].message.content;
        console.log(`ü§ñ [Batch ${batchIndex + 1}] Ph√¢n t√≠ch ho√†n ch·ªânh:`);
        console.log(analysisText);

        // Parse JSON t·ª´ response
        let batchAnalysis;
        try {
            const jsonMatch = analysisText.match(/\{[\s\S]*\}/);
            if (jsonMatch) {
                batchAnalysis = JSON.parse(jsonMatch[0]);

                // L∆∞u theme/color/style t·ª´ batch ƒë·∫ßu ti√™n
                if (batchIndex === 0) {
                    overallTheme = batchAnalysis.overallTheme;
                    colorScheme = batchAnalysis.colorScheme;
                    visualStyle = batchAnalysis.visualStyle;
                    console.log(`‚úÖ [Batch 1] Ch·ªß ƒë·ªÅ ch√≠nh: ${overallTheme}`);
                    console.log(`‚úÖ [Batch 1] M√†u s·∫Øc: ${colorScheme}`);
                    console.log(`‚úÖ [Batch 1] Phong c√°ch: ${visualStyle}`);
                } else {
                    console.log(`‚úÖ [Batch ${batchIndex + 1}] Ti·∫øp t·ª•c ch·ªß ƒë·ªÅ: ${overallTheme}`);
                }

                // Th√™m segments v√†o allSegments
                allSegments.push(...batchAnalysis.segments);
                console.log(`‚úÖ [Batch ${batchIndex + 1}] ƒê√£ th√™m ${batchAnalysis.segments.length} segments (t·ªïng: ${allSegments.length}/${TOTAL_SEGMENTS})`);
            } else {
                throw new Error('No JSON found in response');
            }
        } catch (parseError) {
            console.error(`‚ùå [Batch ${batchIndex + 1}] Kh√¥ng th·ªÉ parse JSON t·ª´ ChatGPT:`, parseError.message);
            throw new Error('ChatGPT kh√¥ng tr·∫£ v·ªÅ JSON h·ª£p l·ªá. Vui l√≤ng th·ª≠ l·∫°i.');
        }

        } // K·∫øt th√∫c v√≤ng l·∫∑p batch

        // T·∫°o analysis object t·ªïng h·ª£p t·ª´ t·∫•t c·∫£ batches
        const analysis = {
            overallTheme,
            colorScheme,
            visualStyle,
            segments: allSegments
        };

        console.log(`\n‚úÖ [Step 2] Ho√†n th√†nh ${NUM_BATCHES} batches v·ªõi ${allSegments.length} segments!`);
        console.log(`‚úÖ [Step 2] Ch·ªß ƒë·ªÅ: ${overallTheme}`);
        console.log(`‚úÖ [Step 2] M√†u s·∫Øc: ${colorScheme}`);
        console.log(`‚úÖ [Step 2] Phong c√°ch: ${visualStyle}`);
        
        // L·∫•y cookie tr∆∞·ªõc khi t·∫°o videos (ch·ªâ l·∫•y 1 l·∫ßn cho t·∫•t c·∫£)
        console.log('üç™ [Step 3] L·∫•y/cache cookie tr∆∞·ªõc khi t·∫°o videos...');
        await getCachedOrFreshCookie(serverUrl);
        
        // Step 3: T·ªëi ∆∞u h√≥a t·ª´ng prompt v·ªõi ChatGPT tr∆∞·ªõc khi t·∫°o video
        console.log('ü§ñ [Step 3] ChatGPT t·ªëi ∆∞u h√≥a t·ª´ng prompt cho Veo3...');
        
        // X·ª¨ L√ù THEO L√î ƒë·ªÉ nhanh nh∆∞ng v·∫´n an to√†n
        const veo3Results = [];
        const earlyMonitorPromises = [];
        const CONCURRENCY = 5; // gi·∫£m ƒë·ªìng th·ªùi ƒë·ªÉ tr√°nh burst Step 4
        console.log(`‚è±Ô∏è [Step 3] X·ª≠ l√Ω THEO L√î ${analysis.segments.length} segments (concurrency=${CONCURRENCY})`);

        async function monitorAndDownload(veo3Result, opts = {}){
            const { startDelayMs = 0, pollEveryMs = 5000, maxAttempts = 60 } = opts;
            let operationId = veo3Result.operationId;
            let recreateAttempts = 0;
            const maxRecreate = 2;
            const promptForRecreate = veo3Result.optimizedPrompt || veo3Result.originalPrompt || '';
            if (startDelayMs > 0) { await sleep(startDelayMs); }
            console.log(`üîÑ [Monitor] Start op=${operationId} seg=${veo3Result.segmentIndex + 1} delay=${startDelayMs}ms interval=${pollEveryMs}ms`);
            let attempts = 0;
            while (attempts < maxAttempts) {
                try {
                    const statusResponse = await fetch(`${serverUrl}/api/check-status`, {
                        method: 'POST',
                        headers: { 'Content-Type': 'application/json' },
                        body: JSON.stringify({
                            operationName: operationId,
                            noRemove: true,
                            ...(LABS_COOKIES ? { labsCookies: LABS_COOKIES } : {})
                        })
                    });
                    const statusResult = await statusResponse.json();
                    if (statusResult.success && statusResult.videoStatus === 'COMPLETED' && statusResult.videoUrl) {
                        const downloadResponse = await fetch(`${serverUrl}/api/tts/download`, {
                            method: 'POST', headers: { 'Content-Type': 'application/json' },
                            body: JSON.stringify({ audioUrl: statusResult.videoUrl, filename: `video_segment_${veo3Result.segmentIndex}_${Date.now()}.mp4` })
                        });
                        const downloadResult = await downloadResponse.json();
                        if (downloadResult.success) {
                            const videoPath = downloadResult.savedTo || downloadResult.outPath || downloadResult.path;
                            return { success: true, segmentIndex: veo3Result.segmentIndex, path: videoPath, publicPath: downloadResult.publicPath, filename: downloadResult.filename, operationId };
                        }
                        return { success: false, segmentIndex: veo3Result.segmentIndex, error: 'Download failed' };
                    } else if (statusResult.success && statusResult.videoStatus === 'PENDING') {
                        attempts++;
                        await sleep(pollEveryMs);
                    } else {
                        if (recreateAttempts < maxRecreate && promptForRecreate) {
                            recreateAttempts++;
                            try {
                                const veo3Response = await fetch(`${serverUrl}/api/create-video`, {
                                    method: 'POST', headers: { 'Content-Type': 'application/json' },
                                    body: JSON.stringify({ input: promptForRecreate, prompt: promptForRecreate, ...(LABS_COOKIES ? { labsCookies: LABS_COOKIES } : {}) })
                                });
                                const veo3Json = await veo3Response.json();
                                if (veo3Json && veo3Json.success && veo3Json.operationName) {
                                    operationId = veo3Json.operationName; attempts = 0; continue;
                                }
                            } catch (_) {}
                        }
                        return { success: false, segmentIndex: veo3Result.segmentIndex, error: 'Operation failed' };
                    }
                } catch (e) {
                    attempts++;
                    await sleep(pollEveryMs);
                }
            }
            return { success: false, segmentIndex: veo3Result.segmentIndex, error: 'Timeout' };
        }

        async function processOneSegment(index) {
            const segment = analysis.segments[index];
            console.log(`ü§ñ [Step 3] T·ªëi ∆∞u segment ${index + 1}: ${segment.timeRange}`);
            console.log(`ü§ñ [Step 3] Focus: ${segment.focus}`);

            try {
                // T·∫°o context v·ªÅ segments tr∆∞·ªõc/sau ƒë·ªÉ ƒë·∫£m b·∫£o li√™n k·∫øt
                const prevSegment = index > 0 ? analysis.segments[index - 1] : null;
                const nextSegment = index < analysis.segments.length - 1 ? analysis.segments[index + 1] : null;

                // G·ªçi ChatGPT ƒë·ªÉ t·ªëi ∆∞u prompt v·ªõi format chi ti·∫øt
                const optimizeResult = await fetchOpenAIWithRetry({
                    model: 'gpt-4o-mini',
                    messages: [
                            {
                                role: "system",
                                content: `B·∫°n l√† chuy√™n gia t·ªëi ∆∞u prompt cho Veo 3.1 (Google Video AI m·ªõi nh·∫•t).

Nhi·ªám v·ª•: T·ªëi ∆∞u h√≥a prompt th√†nh JSON array chi ti·∫øt cho video 8 gi√¢y v·ªõi CHUY·ªÇN C·∫¢NH m∆∞·ª£t m√†.

üéØ QUY T·∫ÆC V√ÄNG:
1. CH·ªà t·ªëi ∆∞u visual c·ªßa prompt G·ªêC - KH√îNG ƒë·ªïi n·ªôi dung ch√≠nh
2. KH√îNG th√™m c·∫£nh/y·∫øu t·ªë m·ªõi kh√¥ng c√≥ trong prompt g·ªëc
3. CH·ªà th√™m chi ti·∫øt v·ªÅ: camera, transition, visual details, ambient sound
4. GI·ªÆ NGUY√äN √Ω nghƒ©a v√† n·ªôi dung c·ªßa prompt g·ªëc

‚ö†Ô∏è TUY·ªÜT ƒê·ªêI KH√îNG ƒê∆Ø·ª¢C:
‚ùå KH√îNG c√≥ text/ch·ªØ/subtitle HI·ªÇN TH·ªä trong video
‚ùå KH√îNG c√≥ d√≤ng ch·ªØ b·∫•t k·ª≥ xu·∫•t hi·ªán tr√™n m√†n h√¨nh
‚ùå KH√îNG c√≥ caption, title, watermark hi·ªÉn th·ªã
‚ùå KH√îNG c√≥ voice-over, l·ªùi tho·∫°i, narration, dialogue, speech
‚ùå KH√îNG c√≥ human voice, talking, speaking
‚úÖ CH·ªà c√≥ h√¨nh ·∫£nh thu·∫ßn + √¢m thanh n·ªÅn t·ª± nhi√™n/nh·∫°c n·ªÅn (KH√îNG c√≥ gi·ªçng n√≥i)

Tr·∫£ v·ªÅ ƒê√öNG format JSON array n√†y (4 ph·∫ßn t·ª≠ cho 8 gi√¢y):
[
  {
    "timeStart": 0,
    "timeEnd": 2,
    "action": "M√¥ t·∫£ h√†nh ƒë·ªông KH√îNG C√ì CH·ªÆ HI·ªÇN TH·ªä, KH√îNG C√ì GI·ªåNG N√ìI, ch·ªâ visual thu·∫ßn",
    "cameraStyle": "Phong c√°ch camera (zoom in, pan left, tilt up, steady shot, etc)",
    "transition": "Chuy·ªÉn c·∫£nh t·ª´ scene tr∆∞·ªõc (fade in, dissolve, cut, pan transition, zoom transition, etc)",
    "soundFocus": "√Çm thanh n·ªÅn t·ª± nhi√™n/nh·∫°c n·ªÅn (ambient sounds, background music, nature sounds, sound effects - TUY·ªÜT ƒê·ªêI KH√îNG voice-over/speech/dialogue/narration)",
    "visualDetails": "Chi ti·∫øt visual (m√†u s·∫Øc, √°nh s√°ng, texture, shadows, etc) - KH√îNG CH·ªÆ HI·ªÇN TH·ªä, KH√îNG GI·ªåNG N√ìI"
  },
  ...
]

Y√äU C·∫¶U CHUY·ªÇN C·∫¢NH:
- Scene ƒë·∫ßu ti√™n: transition li√™n k·∫øt v·ªõi segment tr∆∞·ªõc (ho·∫∑c fade in n·∫øu l√† segment ƒë·∫ßu)
- C√°c scenes gi·ªØa: transition m∆∞·ª£t m√† (dissolve, smooth pan, gradual zoom)
- Scene cu·ªëi c√πng: transition chu·∫©n b·ªã cho segment sau (ho·∫∑c fade out n·∫øu l√† segment cu·ªëi)

CH·ªà tr·∫£ v·ªÅ JSON array, KH√îNG c√≥ gi·∫£i th√≠ch hay text kh√°c.` 
                            },
                            {
                                role: "user",
                                content: `T·ªëi ∆∞u prompt n√†y th√†nh JSON array chi ti·∫øt cho video 8 gi√¢y v·ªõi CHUY·ªÇN C·∫¢NH m∆∞·ª£t m√†:

üé¨ CH·ª¶ ƒê·ªÄ CH√çNH C·ª¶A TO√ÄN B·ªò VIDEO: ${analysis.overallTheme}
üé® M√ÄU S·∫ÆC ƒê·ªíNG NH·∫§T: ${analysis.colorScheme}
üìπ PHONG C√ÅCH: ${analysis.visualStyle}

üìç SEGMENT HI·ªÜN T·∫†I ${index + 1}/${analysis.segments.length}: ${segment.timeRange}
üìå FOCUS C·ª¶A SEGMENT N√ÄY: ${segment.focus}
üìù ORIGINAL PROMPT: ${segment.prompt}

‚ö†Ô∏è QUAN TR·ªåNG - VIDEO KH√îNG C√ì THO·∫†I:
- Video n√†y CH·ªà c√≥ visual thu·∫ßn t√∫y + √¢m thanh n·ªÅn t·ª± nhi√™n/nh·∫°c n·ªÅn
- TUY·ªÜT ƒê·ªêI KH√îNG c√≥ voice-over, l·ªùi tho·∫°i, narration, dialogue, speech
- TUY·ªÜT ƒê·ªêI KH√îNG c√≥ human voice, talking, speaking, narrator
- KH√îNG hi·ªÉn th·ªã text/ch·ªØ trong video
- CH·ªà c√≥ h√¨nh ·∫£nh ƒë·ªông + √¢m thanh n·ªÅn (ambient sounds, music, nature sounds, sound effects)

‚ö†Ô∏è QUAN TR·ªåNG: M·ªói scene PH·∫¢I N√äU R√ï ch·ªß ƒë·ªÅ "${analysis.overallTheme}" trong action description.
   - V√≠ d·ª•: Thay v√¨ "H√¨nh ·∫£nh m√°y bay bay" ‚Üí "H√¨nh ·∫£nh m√°y bay MH370 bay qua v√πng tr·ªùi (ch·ªß ƒë·ªÅ: ${analysis.overallTheme})"
   - M·ªói action PH·∫¢I b·∫Øt ƒë·∫ßu b·∫±ng context v·ªÅ ch·ªß ƒë·ªÅ ch√≠nh ƒë·ªÉ Veo3 hi·ªÉu r√µ c√¢u chuy·ªán

B·ªêI C·∫¢NH LI√äN K·∫æT:
${prevSegment ? `- SEGMENT TR∆Ø·ªöC (${prevSegment.timeRange}): ${prevSegment.focus}
  ‚Üí Scene ƒë·∫ßu ti√™n (0-2s) c·∫ßn transition m∆∞·ª£t m√† t·ª´ segment tr∆∞·ªõc
  ‚Üí Prompt g·ªëc segment tr∆∞·ªõc: ${prevSegment.prompt}` : '- ƒê√ÇY L√Ä SEGMENT ƒê·∫¶U TI√äN\n  ‚Üí Scene ƒë·∫ßu (0-2s) d√πng "fade in" ho·∫∑c "slow zoom in" ƒë·ªÉ m·ªü m√†n'}

${nextSegment ? `- SEGMENT SAU (${nextSegment.timeRange}): ${nextSegment.focus}
  ‚Üí Scene cu·ªëi c√πng (6-8s) c·∫ßn transition chu·∫©n b·ªã cho segment sau
  ‚Üí Prompt g·ªëc segment sau: ${nextSegment.prompt}` : '- ƒê√ÇY L√Ä SEGMENT CU·ªêI C√ôNG\n  ‚Üí Scene cu·ªëi (6-8s) d√πng "fade out" ho·∫∑c "slow zoom out" ƒë·ªÉ k·∫øt th√∫c'}

üéØ Y√äU C·∫¶U TUY·ªÜT ƒê·ªêI:
1. GI·ªÆ NGUY√äN N·ªòI DUNG c·ªßa ORIGINAL PROMPT: "${segment.prompt}"
   - KH√îNG th√™m y·∫øu t·ªë m·ªõi kh√¥ng c√≥ trong prompt g·ªëc
   - KH√îNG ƒë·ªïi √Ω nghƒ©a ch√≠nh c·ªßa prompt g·ªëc
   - CH·ªà chia nh·ªè th√†nh 4 scenes (0-2s, 2-4s, 4-6s, 6-8s) v√† th√™m chi ti·∫øt k·ªπ thu·∫≠t

2. CHI TI·∫æT C·∫¶N TH√äM (kh√¥ng ƒë·ªïi n·ªôi dung):
   - action: M√¥ t·∫£ visual ƒê√öNG v·ªõi prompt g·ªëc - PH·∫¢I N√äU R√ï CH·ª¶ ƒê·ªÄ "${analysis.overallTheme}" - KH√îNG TEXT/CH·ªÆ/GI·ªåNG N√ìI
     V√ç D·ª§: "H√¨nh ·∫£nh m√°y bay MH370 c·∫•t c√°nh (ch·ªß ƒë·ªÅ: cu·ªôc t√¨m ki·∫øm MH370), v·ªõi √°nh s√°ng m·ªù ·∫£o"
     KH√îNG ƒê∆Ø·ª¢C: "H√¨nh ·∫£nh m√°y bay c·∫•t c√°nh" (thi·∫øu context ch·ªß ƒë·ªÅ)
   - cameraStyle: camera movement (zoom in/out, pan left/right/up/down, tilt, steady, tracking shot)
   - transition: chuy·ªÉn c·∫£nh (fade, dissolve, cut, smooth pan, cross dissolve, match cut)
   - soundFocus: √¢m thanh n·ªÅn t·ª± nhi√™n/nh·∫°c n·ªÅn (ambient sounds, background music, nature sounds, sound effects - TUY·ªÜT ƒê·ªêI KH√îNG voice-over/speech/dialogue/narration/human voice)
   - visualDetails: m√†u ${analysis.colorScheme}, phong c√°ch ${analysis.visualStyle}, lighting, texture, atmosphere

‚ö†Ô∏è TUY·ªÜT ƒê·ªêI KH√îNG ƒê∆Ø·ª¢C:
- KH√îNG th√™m c·∫£nh/ƒë·ªëi t∆∞·ª£ng/h√†nh ƒë·ªông m·ªõi kh√¥ng c√≥ trong ORIGINAL PROMPT
- KH√îNG c√≥ text overlay, subtitle, caption, ch·ªØ vi·∫øt b·∫•t k·ª≥
- KH√îNG c√≥ voice-over, l·ªùi tho·∫°i, narration, dialogue, speech, human voice, talking, speaking, narrator
- CH·ªà visual thu·∫ßn: objects, scenes, actions, movements t·ª´ ORIGINAL PROMPT
- CH·ªà √¢m thanh n·ªÅn: ambient sounds, background music, nature sounds, sound effects (KH√îNG gi·ªçng n√≥i)
- NH∆ØNG PH·∫¢I N√äU R√ï CH·ª¶ ƒê·ªÄ "${analysis.overallTheme}" trong m·ªói action ƒë·ªÉ Veo3 hi·ªÉu context c√¢u chuy·ªán

QUAN TR·ªåNG V·ªÄ TRANSITION GI·ªÆA SEGMENTS:
- Scene 1 (0-2s): PH·∫¢I transition m∆∞·ª£t m√† T·ª™ ${prevSegment ? `"${prevSegment.focus}" c·ªßa segment tr∆∞·ªõc` : 'm√†n h√¨nh ƒëen v·ªõi fade in'}
  ${prevSegment ? `‚Üí Visual ph·∫£i li√™n k·∫øt v·ªõi scene cu·ªëi segment tr∆∞·ªõc, d√πng cross dissolve, match cut ho·∫∑c smooth pan` : '‚Üí Fade in t·ª´ ƒëen, ho·∫∑c slow zoom in'}
- Scenes 2-3 (2-6s): transition m∆∞·ª£t gi·ªØa c√°c scenes TRONG segment n√†y
  ‚Üí D√πng dissolve, smooth camera movement ƒë·ªÉ k·∫øt n·ªëi
- Scene 4 (6-${SEGMENT_DURATION}s): PH·∫¢I chu·∫©n b·ªã transition SANG ${nextSegment ? `"${nextSegment.focus}" c·ªßa segment sau` : 'k·∫øt th√∫c v·ªõi fade out'}
  ${nextSegment ? `‚Üí Visual v√† camera ph·∫£i setup cho scene ƒë·∫ßu segment sau, t·∫°o continuity` : '‚Üí Fade out ho·∫∑c slow zoom out ƒë·ªÉ k·∫øt th√∫c'}

üé¨ M·ª§C TI√äU: ${analysis.segments.length} segments gh√©p l·∫°i ph·∫£i li·ªÅn m·∫°ch nh∆∞ 1 video duy nh·∫•t!

üìã V√ç D·ª§ TRANSITION T·ªêT (d·ª±a theo n·ªôi dung):
- Segment k·∫øt th√∫c v·ªõi "object xa d·∫ßn" 
  ‚Üí Segment sau b·∫Øt ƒë·∫ßu "zoom v√†o object m·ªõi" (li√™n k·∫øt: movement continuity)
- Segment k·∫øt th√∫c v·ªõi "scene r·ªông" 
  ‚Üí Segment sau b·∫Øt ƒë·∫ßu "close-up detail" (li√™n k·∫øt: scale transition)
- Segment k·∫øt th√∫c v·ªõi "m√†u s√°ng"
  ‚Üí Segment sau b·∫Øt ƒë·∫ßu "m√†u t∆∞∆°ng t·ª±" (li√™n k·∫øt: color continuity)
- Segment k·∫øt th√∫c v·ªõi "camera pan right"
  ‚Üí Segment sau b·∫Øt ƒë·∫ßu "camera continues panning" (li√™n k·∫øt: motion continuity)

CH·ªà tr·∫£ v·ªÅ JSON array, KH√îNG th√™m text n√†o kh√°c.` 
                            }
                        ],
                        max_tokens: 1500,
                        temperature: 0.3 // Th·∫•p ƒë·ªÉ gi·ªØ ƒë√∫ng n·ªôi dung, kh√¥ng s√°ng t·∫°o th√™m
                });

                if (!optimizeResult.choices) {
                    throw new Error('ChatGPT optimization failed');
                }

                const optimizedContent = optimizeResult.choices[0].message.content.trim();

                // Parse JSON array t·ª´ response
                let detailedTimeline;
                try {
                    const jsonMatch = optimizedContent.match(/\[[\s\S]*\]/);
                    if (jsonMatch) {
                        detailedTimeline = JSON.parse(jsonMatch[0]);
                    } else {
                        throw new Error('No JSON array found in response');
                    }
                } catch (parseError) {
                    console.warn(`‚ö†Ô∏è [Step 3] Kh√¥ng parse ƒë∆∞·ª£c JSON, d√πng prompt g·ªëc`);
                    detailedTimeline = null;
                }

                // Convert JSON array th√†nh string prompt cho Veo 3.1
                let optimizedPrompt;
                if (detailedTimeline && Array.isArray(detailedTimeline)) {
                    // Th√™m context ch·ªß ƒë·ªÅ v√†o ƒë·∫ßu prompt
                    const themeContext = `[CONTEXT: ${analysis.overallTheme}. Style: ${analysis.visualStyle}. Colors: ${analysis.colorScheme}] `;

                    // Convert chi ti·∫øt timeline th√†nh string description (TUY·ªÜT ƒê·ªêI KH√îNG c√≥ voice-over/speech)
                    const scenesDescription = detailedTimeline.map(scene => {
                        const transitionText = scene.transition ? `Transition: ${scene.transition}.` : '';
                        // ƒê·∫£m b·∫£o soundFocus KH√îNG ch·ª©a voice-over/speech
                        const soundText = scene.soundFocus ? scene.soundFocus.replace(/voice-over|voice over|narration|dialogue|speech|talking|speaking|narrator|human voice/gi, 'ambient sound') : 'ambient sound';
                        return `[${scene.timeStart}-${scene.timeEnd}s] ${transitionText} ${scene.action}. Camera: ${scene.cameraStyle}. Visual: ${scene.visualDetails}. Sound: ${soundText} (NO voice-over, NO speech, NO dialogue).`;
                    }).join(' ');

                    // K·∫øt h·ª£p context + scenes (TUY·ªÜT ƒê·ªêI KH√îNG c√≥ voice-over/speech)
                    optimizedPrompt = themeContext + scenesDescription + ' [IMPORTANT: NO voice-over, NO narration, NO dialogue, NO speech, NO human voice in the entire video. Only visual content with ambient sounds/background music.]';

                    console.log(`‚úÖ [Step 3] Segment ${index + 1} optimized v·ªõi ${detailedTimeline.length} scenes chi ti·∫øt:`);
                    detailedTimeline.forEach(scene => {
                        console.log(`   [${scene.timeStart}-${scene.timeEnd}s] ${scene.action}`);
                        if (scene.transition) {
                            console.log(`      üîÑ Transition: ${scene.transition}`);
                        }
                        console.log(`      üìπ Camera: ${scene.cameraStyle}`);
                        console.log(`      üé® Visual: ${scene.visualDetails}`);
                        console.log(`      üîä Sound: ${scene.soundFocus}`);
                    });
                } else {
                    // Fallback: d√πng prompt g·ªëc + th√™m ch·ªâ th·ªã KH√îNG c√≥ voice-over
                    optimizedPrompt = segment.prompt + ' [IMPORTANT: NO voice-over, NO narration, NO dialogue, NO speech, NO human voice. Only visual content with ambient sounds/background music.]';
                    console.log(`‚ö†Ô∏è [Step 3] Segment ${index + 1} d√πng prompt g·ªëc + ch·ªâ th·ªã NO voice-over`);
                }

                // T·∫°o video v·ªõi retry mechanism (exponential backoff)
                console.log(`üé¨ [Step 3] T·∫°o video segment ${index + 1} v·ªõi prompt string t·ªëi ∆∞u...`);

                let veo3Result = null;
                let retryCount = 0;
                const maxRetries = 10; // TƒÉng l√™n 10 l·∫ßn retry

                while (retryCount < maxRetries) {
                    try {
                        const veo3Response = await fetch(`${serverUrl}/api/create-video`, {
                            method: 'POST',
                            headers: { 'Content-Type': 'application/json' },
                            body: JSON.stringify({
                                input: optimizedPrompt,
                                prompt: optimizedPrompt,
                                ...(LABS_COOKIES ? { labsCookies: LABS_COOKIES } : {}),
                                ...(VEO_PROJECT_ID ? { projectId: VEO_PROJECT_ID } : {})
                            })
                        });

                        veo3Result = await veo3Response.json();

                        if (veo3Result.success) {
                            break; // Th√†nh c√¥ng, tho√°t v√≤ng l·∫∑p
                        } else {
                            throw new Error(veo3Result.message || 'Create video failed');
                        }
                    } catch (error) {
                        retryCount++;
                        console.log(`‚ö†Ô∏è [Step 3] Segment ${index + 1} th·∫•t b·∫°i l·∫ßn ${retryCount}/${maxRetries}: ${error.message}`);

                        if (retryCount < maxRetries) {
                            // Exponential backoff: 2^retryCount * 2 gi√¢y (2s, 4s, 8s, 16s, 32s, 64s, 128s)
                            const waitTime = Math.pow(2, retryCount) * 2000;
                            const waitSeconds = Math.floor(waitTime / 1000);
                            console.log(`‚è≥ [Step 3] ƒê·ª£i ${waitSeconds}s tr∆∞·ªõc khi retry (exponential backoff)...`);
                            await new Promise(resolve => setTimeout(resolve, waitTime));

                            // Refresh cookie n·∫øu l·ªói li√™n quan ƒë·∫øn cookie
                            if (error.message.includes('cookie') || error.message.includes('Chrome Labs')) {
                                console.log(`üîÑ [Step 3] Refresh cookie...`);
                                cachedCookie = null; // X√≥a cache
                                await getCachedOrFreshCookie(serverUrl);
                            }
                        }
                    }
                }

                if (veo3Result && veo3Result.success) {
                    console.log(`‚úÖ [Step 3] Segment ${index + 1} Veo3: ${veo3Result.operationName}`);
                    const resultObj = {
                        segmentIndex: index,
                        timeRange: segment.timeRange,
                        focus: segment.focus,
                        originalPrompt: segment.prompt,
                        detailedTimeline: detailedTimeline,
                        optimizedPrompt: optimizedPrompt,
                        operationId: veo3Result.operationName,
                        success: true
                    };
                    // Kh·ªüi ƒë·ªông theo d√µi s·ªõm sau 60s, poll m·ªói 10s
                    earlyMonitorPromises.push(monitorAndDownload(resultObj, { startDelayMs: 60000, pollEveryMs: 10000, maxAttempts: 36 }));
                    return resultObj;
                } else {
                    console.log(`‚ùå [Step 3] Segment ${index + 1} th·∫•t b·∫°i sau ${maxRetries} l·∫ßn th·ª≠`);
                    return {
                        segmentIndex: index,
                        timeRange: segment.timeRange,
                        error: veo3Result?.message || 'Failed after retries',
                        success: false
                    };
                }
            } catch (error) {
                console.log(`‚ùå [Step 3] Segment ${index + 1} l·ªói: ${error.message}`);
                return {
                    segmentIndex: index,
                    timeRange: segment.timeRange,
                    error: error.message,
                    success: false
                };
            }
        }

        for (let start = 0; start < analysis.segments.length; start += CONCURRENCY) {
            const end = Math.min(start + CONCURRENCY, analysis.segments.length);
            const indexes = Array.from({ length: end - start }, (_, i) => start + i);
            // gi√£n c√°ch nh·∫π gi·ªØa c√°c request trong c√πng l√¥ ƒë·ªÉ gi·∫£m burst
            const tasks = indexes.map((idx, offset) => (async () => {
                if (offset > 0) await new Promise(r => setTimeout(r, 200 * offset));
                return await processOneSegment(idx);
            })());
            const batchResults = await Promise.all(tasks);
            veo3Results.push(...batchResults);
            // ngh·ªâ 1s gi·ªØa c√°c l√¥
            if (end < analysis.segments.length) await new Promise(r => setTimeout(r, 1000));
        }

        // T·∫•t c·∫£ requests ƒë√£ ho√†n th√†nh (x·ª≠ l√Ω tu·∫ßn t·ª±)
        const successfulOperations = veo3Results.filter(r => r.success);
        
        console.log(`‚úÖ [Step 3] ƒê√£ t·ªëi ∆∞u v√† g·ª≠i ${successfulOperations.length}/${analysis.segments.length} Veo3 requests`);
        console.log(`üöÄ [Step 3] T·∫•t c·∫£ Veo3 ƒëang ch·∫°y ng·∫ßm v·ªõi prompt ƒë√£ t·ªëi ∆∞u...`);
        
        // Step 4: Ch·∫°y ng·∫ßm - ki·ªÉm tra v√† t·∫£i video khi s·∫µn s√†ng (throttle)
        console.log(`üîÑ [Step 4] Ch·∫°y ng·∫ßm - ki·ªÉm tra v√† t·∫£i video khi s·∫µn s√†ng...`);
        const MONITOR_CONCURRENCY = 3; // gi·ªõi h·∫°n s·ªë op theo d√µi c√πng l√∫c

        async function monitorAndDownloadLate(veo3Result){
            let operationId = veo3Result.operationId;
            let recreateAttempts = 0;
            const maxRecreate = 2; // t·∫°o l·∫°i t·ªëi ƒëa 2 l·∫ßn ƒë·ªÉ tr√°nh thi·∫øu video
            const promptForRecreate = veo3Result.optimizedPrompt || veo3Result.originalPrompt || '';
            console.log(`üîÑ [Step 4] Monitor operation: ${operationId}`);
            
            // Polling ƒë·ªÉ ki·ªÉm tra tr·∫°ng th√°i
            let attempts = 0;
            const maxAttempts = 60; // T·ªëi ƒëa 60 l·∫ßn (5 ph√∫t)
            
            while (attempts < maxAttempts) {
                try {
                    const statusResponse = await fetch(`${serverUrl}/api/check-status`, {
                        method: 'POST',
                        headers: { 'Content-Type': 'application/json' },
                        body: JSON.stringify({
                            operationName: operationId,
                            noRemove: true,
                            ...(LABS_COOKIES ? { labsCookies: LABS_COOKIES } : {})
                        })
                    });
                    
                    const statusResult = await statusResponse.json();
                    
                    if (statusResult.success && statusResult.videoStatus === 'COMPLETED' && statusResult.videoUrl) {
                        console.log(`‚úÖ [Step 4] Operation ${operationId} ƒë√£ ho√†n th√†nh!`);
                        
                        // T·∫£i video
                        const downloadResponse = await fetch(`${serverUrl}/api/tts/download`, {
                            method: 'POST',
                            headers: { 'Content-Type': 'application/json' },
                            body: JSON.stringify({
                                audioUrl: statusResult.videoUrl,
                                filename: `video_segment_${veo3Result.segmentIndex}_${Date.now()}.mp4`
                            })
                        });
                        
                        const downloadResult = await downloadResponse.json();
                        
                        if (downloadResult.success) {
                            // API tr·∫£ v·ªÅ savedTo, kh√¥ng ph·∫£i outPath
                            const videoPath = downloadResult.savedTo || downloadResult.outPath || downloadResult.path;
                            console.log(`‚úÖ [Step 4] Segment ${veo3Result.segmentIndex + 1} ƒë√£ t·∫£i v·ªÅ`);
                            console.log(`‚úÖ [Step 4] Video path: ${videoPath}`);
                            console.log(`‚úÖ [Step 4] Public path: ${downloadResult.publicPath}`);
                            return {
                                segmentIndex: veo3Result.segmentIndex,
                                timeRange: veo3Result.timeRange,
                                focus: veo3Result.focus,
                                path: videoPath,
                                publicPath: downloadResult.publicPath,
                                filename: downloadResult.filename,
                                operationId: operationId,
                                success: true
                            };
                        } else {
                            console.log(`‚ùå [Step 4] Segment ${veo3Result.segmentIndex + 1} t·∫£i v·ªÅ th·∫•t b·∫°i: ${downloadResult.message}`);
                            return {
                                segmentIndex: veo3Result.segmentIndex,
                                error: 'Download failed',
                                success: false
                            };
                        }
                    } else if (statusResult.success && statusResult.videoStatus === 'PENDING') {
                        console.log(`‚è≥ [Step 4] Operation ${operationId} ƒëang x·ª≠ l√Ω... (attempt ${attempts + 1})`);
                        attempts++;
                        await new Promise(resolve => setTimeout(resolve, 5000)); // Ch·ªù 5 gi√¢y
                    } else {
                        // Th·ª≠ t·∫°o l·∫°i operation m·ªõi n·∫øu c√≤n l∆∞·ª£t
                        if (recreateAttempts < maxRecreate && promptForRecreate) {
                            recreateAttempts++;
                            console.log(`‚ôªÔ∏è  [Step 4] Operation ${operationId} th·∫•t b·∫°i/kh√¥ng th·∫•y ‚Üí T·∫†O L·∫†I (l·∫ßn ${recreateAttempts}/${maxRecreate})`);
                            try {
                                const veo3Response = await fetch(`${serverUrl}/api/create-video`, {
                                    method: 'POST',
                                    headers: { 'Content-Type': 'application/json' },
                                    body: JSON.stringify({
                                        input: promptForRecreate,
                                        prompt: promptForRecreate,
                                        ...(LABS_COOKIES ? { labsCookies: LABS_COOKIES } : {}),
                                        ...(VEO_PROJECT_ID ? { projectId: VEO_PROJECT_ID } : {})
                                    })
                                });
                                const veo3Json = await veo3Response.json();
                                if (veo3Json && veo3Json.success && veo3Json.operationName) {
                                    operationId = veo3Json.operationName;
                                    attempts = 0; // reset attempts cho op m·ªõi
                                    console.log(`üîÅ [Step 4] ƒê√£ t·∫°o operation m·ªõi: ${operationId}`);
                                    continue; // quay l·∫°i polling v·ªõi op m·ªõi
                                } else {
                                    console.log(`‚ùå [Step 4] T·∫°o l·∫°i operation th·∫•t b·∫°i: ${veo3Json && veo3Json.message}`);
                                }
                            } catch (e) {
                                console.log(`‚ùå [Step 4] L·ªói t·∫°o l·∫°i operation: ${e.message}`);
                            }
                        }
                        console.log(`‚ùå [Step 4] Operation ${operationId} th·∫•t b·∫°i ho·∫∑c kh√¥ng t√¨m th·∫•y`);
                        return {
                            segmentIndex: veo3Result.segmentIndex,
                            error: 'Operation failed',
                            success: false
                        };
                    }
                } catch (error) {
                    console.warn(`‚ö†Ô∏è [Step 4] L·ªói ki·ªÉm tra operation ${operationId}:`, error.message);
                    attempts++;
                    await new Promise(resolve => setTimeout(resolve, 5000));
                }
            }
            
            console.log(`‚è∞ [Step 4] Operation ${operationId} timeout sau ${maxAttempts} attempts`);
            return {
                segmentIndex: veo3Result.segmentIndex,
                error: 'Timeout',
                success: false
            };
        }

        let videoFiles = [];
        if (earlyMonitorPromises.length > 0) {
            console.log(`‚è±Ô∏è [Step 4] Ch·ªù monitors ƒë√£ kh·ªüi ƒë·ªông t·ª´ Step 3 (${earlyMonitorPromises.length})...`);
            videoFiles = await Promise.all(earlyMonitorPromises);
        } else {
            // Th·ª±c thi theo l√¥ nh·ªè ƒë·ªÉ tr√°nh qu√° t·∫£i
            console.log(`‚è±Ô∏è [Step 4] Theo d√µi ${successfulOperations.length} operations (window=${MONITOR_CONCURRENCY})`);
            for (let i = 0; i < successfulOperations.length; i += MONITOR_CONCURRENCY) {
                const chunk = successfulOperations.slice(i, i + MONITOR_CONCURRENCY);
                const results = await Promise.all(chunk.map(monitorAndDownloadLate));
                videoFiles.push(...results);
                if (i + MONITOR_CONCURRENCY < successfulOperations.length) {
                    await sleep(800); // ngh·ªâ ng·∫Øn gi·ªØa c√°c l√¥
                }
            }
        }
        const successfulVideos = videoFiles.filter(v => v.success);
        
        console.log(`‚úÖ [Step 4] ƒê√£ t·∫£i ${successfulVideos.length}/${successfulOperations.length} video`);
        
        // Step 5: Gh√©p video th√†nh 1 video k·∫øt qu·∫£
        if (successfulVideos.length > 0) {
            console.log(`üé¨ [Step 5] Gh√©p ${successfulVideos.length} video th√†nh 1 video k·∫øt qu·∫£...`);
            
            // S·∫Øp x·∫øp theo th·ª© t·ª±
            successfulVideos.sort((a, b) => a.segmentIndex - b.segmentIndex);
            
            // Ki·ªÉm tra c√°c file video t·ªìn t·∫°i
            const validVideoFiles = successfulVideos.filter(video => {
                if (!video.path || !fs.existsSync(video.path)) {
                    console.warn(`‚ö†Ô∏è [Step 5] File video kh√¥ng t·ªìn t·∫°i: ${video.path}`);
                    return false;
                }
                return true;
            });
            
            if (validVideoFiles.length === 0) {
                throw new Error('Kh√¥ng c√≥ file video h·ª£p l·ªá ƒë·ªÉ gh√©p');
            }
            
            console.log(`üìù [Step 5] C√≥ ${validVideoFiles.length} file video h·ª£p l·ªá ƒë·ªÉ gh√©p`);
            
            // T·∫°o file list cho ffmpeg
            const listPath = path.join(outputDir, 'video_list.txt');
            const listContent = validVideoFiles.map(video => {
                const absolutePath = path.resolve(video.path);
                const normalizedPath = absolutePath.replace(/\\/g, '/');
                return `file '${normalizedPath}'`;
            }).join('\n');
            
            console.log(`üìù [Step 5] T·∫°o file list: ${listPath}`);
            fs.writeFileSync(listPath, listContent, 'utf8');
            
            // Gh√©p video
            const finalVideoPath = path.join(outputDir, `video_${VIDEO_DURATION}s_final_${Date.now()}.mp4`);
            const mergeCmd = `ffmpeg -f concat -safe 0 -i "${listPath}" -c copy "${finalVideoPath}"`;
            
            await execAsync(mergeCmd);
            
            console.log(`‚úÖ [Step 5] ƒê√£ gh√©p video th√†nh: ${finalVideoPath}`);
            
            // L∆∞u k·∫øt qu·∫£ ho√†n ch·ªânh
            const finalResult = {
                timestamp: new Date().toISOString(),
                youtubeUrl: youtubeUrl,
                transcript: transcriptText,
                overallTheme: analysis.overallTheme,
                colorScheme: analysis.colorScheme,
                visualStyle: analysis.visualStyle,
                segmentsCreated: analysis.segments.length,
                veo3OperationsSent: successfulOperations.length,
                videosDownloaded: successfulVideos.length,
                finalVideo: finalVideoPath,
                segments: analysis.segments,
                veo3Results: veo3Results,
                videoFiles: successfulVideos,
                outputDir: outputDir
            };
            
            const resultPath = path.join(outputDir, `video-${VIDEO_DURATION}s-result.json`);
            fs.writeFileSync(resultPath, JSON.stringify(finalResult, null, 2));
            
            console.log(`üìä [Step 5] ƒê√£ l∆∞u k·∫øt qu·∫£ v√†o: ${resultPath}`);
            
            console.log(`üéâ Ho√†n th√†nh t·∫°o video ${VIDEO_DURATION}s!`);
            console.log(`üéâ Video k·∫øt qu·∫£: ${finalVideoPath}`);
            console.log(`üéâ Ch·ªß ƒë·ªÅ: ${analysis.overallTheme}`);
            console.log(`üéâ M√†u s·∫Øc: ${analysis.colorScheme}`);
            
            return {
                success: true,
                result: finalResult
            };
            
        } else {
            throw new Error('Kh√¥ng c√≥ video n√†o ƒë∆∞·ª£c t·∫£i v·ªÅ ƒë·ªÉ gh√©p');
        }
        
    } catch (error) {
        console.error(`‚ùå L·ªói:`, error.message);
        return {
            success: false,
            error: error.message
        };
    }
}

console.log(`üöÄ [START] T·∫°o video t·ª´ YouTube KH√îNG C√ì THO·∫†I (ch·ªâ visual + √¢m thanh n·ªÅn, chia theo transcript)...`);
createMH370Video32s().then(result => {
    if (result.success) {
        console.log('üéâ Ho√†n th√†nh th√†nh c√¥ng!');
        console.log(`üéâ Video: ${result.result.finalVideo}`);
    } else {
        console.log(`‚ùå Th·∫•t b·∫°i: ${result.error}`);
    }
});
